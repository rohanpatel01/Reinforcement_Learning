Starting Training
layer weights:  Parameter containing:
tensor([[-0.1811,  0.0387,  0.0007,  0.0419, -0.0222,  0.1869, -0.0069,  0.0859,
         -0.0376, -0.1561, -0.0782,  0.1005,  0.1275,  0.1710,  0.0806, -0.1376,
         -0.1617, -0.0645, -0.0270,  0.0904,  0.0693,  0.1555,  0.0105,  0.0853,
          0.0550],
        [ 0.0083,  0.1374,  0.1992, -0.0354, -0.1097,  0.1829,  0.0980, -0.0861,
          0.0821, -0.1787, -0.0637,  0.1119, -0.1080,  0.1258, -0.1792, -0.0059,
          0.0460, -0.0860,  0.0276,  0.1446, -0.0764, -0.1583,  0.1250,  0.1091,
          0.0418],
        [-0.0516,  0.1596,  0.0898, -0.1594,  0.1525,  0.1088,  0.1927,  0.0538,
          0.0208,  0.1018,  0.0206,  0.1982, -0.1235, -0.1868, -0.1121, -0.0214,
         -0.0640,  0.0191,  0.1431, -0.0395, -0.1207, -0.0998,  0.0766,  0.0426,
          0.0412],
        [ 0.1047,  0.1914,  0.0992,  0.0746,  0.1579,  0.0046, -0.0089,  0.0673,
         -0.0157,  0.0260,  0.0087,  0.1351,  0.1151, -0.1289, -0.1339, -0.1464,
         -0.0762,  0.0877,  0.1149, -0.0635,  0.0776,  0.1016,  0.0669,  0.1317,
          0.0195],
        [-0.1824, -0.1546, -0.0992,  0.1031,  0.0219,  0.1488, -0.1506,  0.1249,
          0.0582, -0.0753,  0.1267, -0.0681, -0.1012,  0.1991,  0.1163, -0.1496,
         -0.1386, -0.1823, -0.0166,  0.1572,  0.0301, -0.1114,  0.1507,  0.1937,
          0.0532]], dtype=torch.float64, requires_grad=True)
layer weights:  Parameter containing:
tensor([[ 0.0029, -0.1665, -0.1578, -0.1940, -0.0224,  0.0498,  0.1346,  0.0390,
          0.1875,  0.1672,  0.0419, -0.1668, -0.0748, -0.0883, -0.1139,  0.0724,
          0.1373,  0.0115, -0.1634, -0.0347,  0.1472,  0.0240, -0.1613, -0.0890,
         -0.0720],
        [ 0.1537, -0.0557, -0.1226,  0.1668, -0.1383,  0.0480,  0.1974,  0.1708,
          0.1691,  0.0952, -0.0084,  0.0217, -0.1039, -0.1346, -0.1767,  0.1230,
          0.0644, -0.0500, -0.1090, -0.0964,  0.0964,  0.1240,  0.1166, -0.1128,
         -0.1425],
        [ 0.1907, -0.1264, -0.1860,  0.0566, -0.1177, -0.0890,  0.0393,  0.0159,
         -0.1335, -0.1231,  0.1690, -0.0274, -0.1342,  0.0444, -0.1319, -0.1189,
         -0.0179,  0.1674,  0.0604, -0.0135,  0.0809, -0.1767, -0.1211, -0.0030,
          0.1873],
        [ 0.0880, -0.1604, -0.1178,  0.1424,  0.0853, -0.1781,  0.1973, -0.1686,
          0.1629, -0.0338,  0.1517, -0.0959, -0.0773,  0.0921, -0.0255,  0.0341,
          0.0484,  0.1493,  0.1677, -0.1246, -0.0711,  0.0183,  0.1911, -0.1379,
          0.1664],
        [ 0.0831, -0.1523, -0.1932,  0.0269,  0.1169,  0.0333,  0.1958, -0.0535,
         -0.1650,  0.1155,  0.0439,  0.1372, -0.0872,  0.1519, -0.0104, -0.1245,
          0.1545, -0.0141,  0.1145,  0.0637, -0.0511, -0.0183,  0.0768, -0.1410,
          0.0623]], dtype=torch.float64, requires_grad=True)
Summary AFTER training

==============================================
Summary: 
State	Action	Next State	Reward
0 		 0 		  Q(s,a)=  tensor(3.8218, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 1 		  Q(s,a)=  tensor(2.9468, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 2 		  Q(s,a)=  tensor(4.4809, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 3 		  Q(s,a)=  tensor(3.4096, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 4 		  Q(s,a)=  tensor(3.9756, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 0 		  Q(s,a)=  tensor(3.5582, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 1 		  Q(s,a)=  tensor(2.5319, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 2 		  Q(s,a)=  tensor(2.8695, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 3 		  Q(s,a)=  tensor(3.1406, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 4 		  Q(s,a)=  tensor(2.4999, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 0 		  Q(s,a)=  tensor(2.4592, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 1 		  Q(s,a)=  tensor(4.9152, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 2 		  Q(s,a)=  tensor(2.9867, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 3 		  Q(s,a)=  tensor(4.3121, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 4 		  Q(s,a)=  tensor(3.5134, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 0 		  Q(s,a)=  tensor(3.5641, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 1 		  Q(s,a)=  tensor(2.6363, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 2 		  Q(s,a)=  tensor(2.9920, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 3 		  Q(s,a)=  tensor(2.9604, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 4 		  Q(s,a)=  tensor(2.6789, dtype=torch.float64, grad_fn=<SelectBackward0>)
==============================================

Best trajectory: 
Best trajectory from Test Environment
State:  0.061142857142857145  Action:  2  Reward Received:  0
State:  0.6176  Action:  1  Reward Received:  2.0
State:  0.36114285714285715  Action:  0  Reward Received:  0.1
State:  0.061142857142857145  Action:  2  Reward Received:  0
State:  0.6176  Action:  1  Reward Received:  2.0

Total Reward Received:  4.1
Taking a look at model parameters to see if weights are changing
Parameter containing:
tensor([[ 8.3688e-01, -7.8673e-01, -6.2153e-01,  8.6904e-01, -3.6079e-01,
         -9.4749e-01,  4.8082e-02,  1.9312e-01,  5.1354e-02,  2.1708e+00,
         -7.9810e-01, -1.3875e-01, -1.2694e+00,  2.5471e+00, -1.7529e+00,
          5.1415e-01,  1.5751e+00, -5.6897e-01,  2.5658e-01,  2.0600e-01,
          4.7284e-01,  7.5612e-01, -7.1075e-02, -6.2264e-01, -2.5368e+00],
        [-3.0095e-01,  6.4783e-01,  3.2419e-02, -1.6038e+00,  3.1067e-01,
          2.5174e+00, -7.8405e-01, -8.8231e-01,  1.2506e+00, -4.0277e+00,
          1.9117e+00, -1.0743e+00,  1.6819e+00, -6.5041e+00,  3.2858e+00,
         -1.9448e+00, -2.4804e+00,  1.0561e+00, -1.4429e-01, -5.3787e-01,
         -9.7275e-02, -8.1462e-01,  1.5009e+00,  7.7729e-01,  5.8851e+00],
        [ 6.7528e-01, -1.1316e+00, -1.3699e+00, -2.4242e-01, -8.9797e-01,
         -4.4415e-01, -1.4550e+00, -6.2078e-02,  1.0187e+00, -3.6913e-02,
          1.8667e-01,  8.3900e-04, -7.6680e-01, -6.3036e-01,  1.7546e-01,
         -1.7089e+00,  9.5157e-01,  3.1664e-01,  8.8113e-01, -6.4176e-01,
          9.7140e-01,  1.0411e+00,  9.5389e-01, -6.1301e-01,  1.2617e+00],
        [ 3.6121e-02,  2.3018e-01, -3.2995e-02, -6.4215e-01,  3.8964e-01,
          1.2646e+00, -3.8552e-01, -9.4822e-01,  6.2846e-01, -2.1641e+00,
          1.1670e+00, -9.9670e-01,  7.6461e-01, -3.2500e+00,  1.7034e+00,
         -1.0744e+00, -1.3601e+00,  5.8725e-01,  1.4273e-01, -2.7671e-01,
         -2.8354e-01, -6.0346e-01,  1.0341e+00,  3.6757e-01,  3.3448e+00],
        [ 1.2201e-01, -7.3548e-01, -1.1250e+00, -1.0463e+00, -4.2073e-01,
          5.9320e-01, -1.3820e+00, -4.2314e-01,  1.1655e+00, -1.4705e+00,
          7.6163e-01, -1.0368e-01,  1.3313e-01, -2.8872e+00,  1.6048e+00,
         -2.2380e+00, -6.0510e-02,  5.7595e-01,  7.0168e-01, -7.1110e-01,
          5.9137e-01,  6.0361e-01,  1.3415e+00, -3.4686e-01,  3.2534e+00]],
       dtype=torch.float64, requires_grad=True)
Parameter containing:
tensor([3.1408, 3.7060, 4.0077, 3.7392, 3.9300], dtype=torch.float64,
       requires_grad=True)
Starting Training
layer weights:  Parameter containing:
tensor([[ 0.1408, -0.1532,  0.1006, -0.0181, -0.0105, -0.0205,  0.1309, -0.1655,
         -0.0484,  0.0391,  0.0610, -0.0735, -0.0746, -0.0423, -0.0116,  0.1576,
          0.0590, -0.0976, -0.0982, -0.0062,  0.0157,  0.1735,  0.1806, -0.0090,
         -0.1934],
        [-0.0117,  0.1676,  0.0265,  0.0214,  0.1807, -0.1028, -0.1413, -0.0135,
         -0.1109,  0.0898, -0.0779,  0.1517,  0.1378, -0.0752,  0.1256,  0.0384,
         -0.1222,  0.1071,  0.0304, -0.1443,  0.1928,  0.0344,  0.0963, -0.1264,
          0.0699],
        [ 0.1380,  0.0383, -0.0934,  0.0845, -0.0002,  0.0619, -0.1488,  0.1014,
         -0.0678, -0.1375,  0.1954,  0.0234, -0.1075, -0.0286, -0.0226, -0.1163,
          0.1386,  0.1345,  0.1326, -0.1891, -0.1419, -0.0432,  0.0671, -0.1417,
         -0.1769],
        [-0.0053,  0.0999, -0.0810, -0.0800, -0.0258, -0.0240, -0.0717,  0.0194,
          0.1320,  0.0483,  0.0793, -0.1882,  0.1459, -0.1430,  0.0704, -0.1531,
          0.0402, -0.0351, -0.1957,  0.0136,  0.1429, -0.1563, -0.0094,  0.1525,
         -0.0670],
        [-0.0045, -0.0547, -0.0756, -0.0390, -0.0950, -0.0544,  0.1592, -0.1005,
          0.1174, -0.1245,  0.1822,  0.0272, -0.0682,  0.1358,  0.1658,  0.0996,
          0.0066,  0.1496, -0.0649, -0.1625,  0.0294,  0.0444,  0.1720, -0.0524,
         -0.1011]], dtype=torch.float64, requires_grad=True)
layer weights:  Parameter containing:
tensor([[-0.0630,  0.1692,  0.1140, -0.1362, -0.0155, -0.0753, -0.0368,  0.0414,
         -0.0132, -0.1294,  0.0289,  0.0548, -0.1745,  0.1123,  0.1311, -0.0672,
          0.0975,  0.1676,  0.1638, -0.0760,  0.1454,  0.0541,  0.1334, -0.1586,
         -0.0265],
        [ 0.0307, -0.1845,  0.1593, -0.1753,  0.0718, -0.1983,  0.0512,  0.0751,
          0.1191,  0.1957, -0.0319, -0.0999,  0.1498, -0.1238, -0.1464, -0.1547,
          0.0604,  0.0584, -0.0295, -0.0564,  0.0828,  0.0579,  0.1526, -0.0406,
         -0.1090],
        [ 0.0394, -0.0383,  0.1708,  0.0276, -0.1431, -0.1177,  0.0795, -0.1989,
         -0.1749, -0.1192,  0.0762, -0.1312,  0.1633, -0.0635,  0.1778,  0.0411,
          0.1985, -0.0271,  0.0182,  0.1656,  0.1616,  0.1760,  0.0217, -0.0079,
          0.0248],
        [-0.0763, -0.0470, -0.1531, -0.0723, -0.1767, -0.0432,  0.1954,  0.1550,
         -0.0418, -0.0858,  0.0118,  0.0665,  0.0785,  0.1633,  0.0325, -0.0042,
         -0.0541,  0.1858, -0.1531,  0.0124, -0.0508,  0.1210,  0.0091, -0.1248,
         -0.0663],
        [ 0.1982,  0.0670, -0.1566,  0.1083,  0.0760, -0.1772, -0.1330, -0.0965,
          0.1649, -0.1302,  0.1505,  0.1738,  0.1906, -0.1157,  0.1639, -0.1076,
          0.1187,  0.0589, -0.1694, -0.1265,  0.0015,  0.1021, -0.0116, -0.1574,
         -0.1744]], dtype=torch.float64, requires_grad=True)
Summary AFTER training

==============================================
Summary: 
State	Action	Next State	Reward
0 		 0 		  Q(s,a)=  tensor(3.9100, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 1 		  Q(s,a)=  tensor(2.8306, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 2 		  Q(s,a)=  tensor(4.3838, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 3 		  Q(s,a)=  tensor(3.1241, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 4 		  Q(s,a)=  tensor(3.9947, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 0 		  Q(s,a)=  tensor(3.8388, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 1 		  Q(s,a)=  tensor(2.3756, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 2 		  Q(s,a)=  tensor(3.0701, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 3 		  Q(s,a)=  tensor(2.5269, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 4 		  Q(s,a)=  tensor(2.6867, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 0 		  Q(s,a)=  tensor(2.4317, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 1 		  Q(s,a)=  tensor(4.2699, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 2 		  Q(s,a)=  tensor(3.6513, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 3 		  Q(s,a)=  tensor(3.5256, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 4 		  Q(s,a)=  tensor(3.5776, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 0 		  Q(s,a)=  tensor(3.7282, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 1 		  Q(s,a)=  tensor(1.9731, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 2 		  Q(s,a)=  tensor(3.4598, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 3 		  Q(s,a)=  tensor(2.1462, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 4 		  Q(s,a)=  tensor(2.8130, dtype=torch.float64, grad_fn=<SelectBackward0>)
==============================================

Best trajectory: 
Best trajectory from Test Environment
State:  0.07474285714285715  Action:  2  Reward Received:  0
State:  0.6512  Action:  1  Reward Received:  2.0
State:  0.36205714285714286  Action:  0  Reward Received:  0.1
State:  0.07474285714285715  Action:  2  Reward Received:  0
State:  0.6512  Action:  1  Reward Received:  2.0

Total Reward Received:  4.1
Taking a look at model parameters to see if weights are changing
Parameter containing:
tensor([[ 0.5222, -1.1334, -0.8005, -0.9306, -1.8203, -0.4364, -1.1264, -0.0443,
         -0.4277, -1.0988,  1.4839,  0.6444,  1.4266,  1.7029, -0.6579, -0.5539,
         -0.2813, -1.5406,  0.7674, -1.6519,  0.4084,  1.8750,  1.6317,  1.5541,
          0.1566],
        [-0.0604,  1.1545,  0.8420,  1.6107,  2.9787,  0.1630,  2.1528,  0.6300,
         -0.2362,  1.8679, -1.5447, -1.8311, -1.8442, -3.4036,  1.0834,  0.3829,
          0.0838,  2.2729, -0.8022,  2.1245, -0.7746, -2.6832, -3.0171, -1.7449,
          0.4031],
        [ 2.4267, -0.8185,  0.3179,  0.8686, -0.2888,  0.7034,  0.1899, -0.2231,
         -2.1343, -0.5272,  0.7937, -0.8616,  0.3800, -0.4356,  1.1082, -0.8150,
         -1.0548,  0.4079,  0.0566,  1.0653,  0.0059, -0.7955, -2.3430,  0.4034,
          0.8260],
        [ 0.2766,  0.4928,  0.1325,  1.0807,  1.4255,  0.2222,  1.4121,  0.5005,
         -0.6286,  0.7943, -0.6283, -1.0906, -0.9205, -1.7952,  0.8185,  0.1420,
         -0.2862,  1.4033, -0.5573,  1.2916, -0.6095, -1.4863, -2.1318, -0.8776,
          0.4109],
        [ 2.2528, -0.2402,  0.2297,  1.2117,  0.6010,  0.6786,  0.3986, -0.0434,
         -1.5738, -0.1371,  0.3728, -0.7794, -0.1279, -1.0990,  1.2877, -0.7344,
         -0.9434,  1.0124, -0.3281,  1.2132, -0.2730, -1.4442, -2.8285, -0.2906,
          0.5768]], dtype=torch.float64, requires_grad=True)
Parameter containing:
tensor([3.7385, 2.6788, 3.8971, 2.9429, 3.6225], dtype=torch.float64,
       requires_grad=True)
Starting Training
layer weights:  Parameter containing:
tensor([[ 0.1621, -0.0655,  0.0720, -0.0855, -0.0849,  0.1421, -0.0701, -0.1950,
          0.1874,  0.0230, -0.0092, -0.1743, -0.0693, -0.0627,  0.0616, -0.1819,
         -0.0526,  0.0088, -0.1451, -0.0718,  0.0499, -0.1243, -0.0848, -0.0477,
          0.0407],
        [ 0.1019, -0.0935, -0.0920, -0.0254,  0.0232, -0.0033,  0.1214, -0.0819,
          0.1936,  0.1438, -0.0578,  0.0751,  0.0844, -0.0182,  0.0618,  0.1865,
         -0.0407,  0.1414,  0.1166,  0.1574,  0.0936, -0.0669, -0.1056, -0.1577,
         -0.0918],
        [ 0.1362,  0.1199,  0.1492, -0.1227,  0.1815,  0.0128, -0.1444, -0.0487,
         -0.0231,  0.0804, -0.1220, -0.1148, -0.0359, -0.1375, -0.1142,  0.0309,
         -0.0349, -0.1623, -0.1946, -0.0969,  0.1026, -0.0232,  0.1429, -0.0542,
         -0.0928],
        [-0.0612, -0.1253,  0.1329,  0.1000, -0.1497,  0.1500, -0.0033,  0.1570,
         -0.0566,  0.1045, -0.1378,  0.0493,  0.0227, -0.0715,  0.0899,  0.0234,
          0.0051,  0.0248,  0.1517, -0.0585, -0.1785, -0.1012,  0.0980,  0.1625,
          0.1860],
        [ 0.0487, -0.0811, -0.0552,  0.0828, -0.0114,  0.0913,  0.1572, -0.0974,
         -0.0288,  0.1204,  0.0308, -0.1432, -0.0334,  0.1367,  0.1983, -0.1485,
         -0.1202, -0.1949,  0.1070, -0.0368,  0.0387,  0.1350,  0.1885,  0.1004,
          0.0669]], dtype=torch.float64, requires_grad=True)
layer weights:  Parameter containing:
tensor([[ 0.1273, -0.0063,  0.1094,  0.1797,  0.0797,  0.0127,  0.0394, -0.0587,
          0.1047, -0.1761, -0.0372, -0.0332,  0.0552, -0.1844, -0.0313, -0.0170,
         -0.0603,  0.0156,  0.0819,  0.0191,  0.0171, -0.0316, -0.0409,  0.1778,
          0.0860],
        [-0.0649,  0.0916, -0.1970, -0.1183, -0.1185,  0.0965, -0.0503, -0.1024,
          0.1647, -0.0196,  0.1249, -0.1048,  0.0820,  0.1359, -0.1735,  0.0798,
         -0.1702,  0.1886,  0.1468, -0.1276,  0.0685, -0.0633,  0.0853,  0.1225,
         -0.1948],
        [ 0.0872, -0.1187, -0.0735,  0.1868,  0.1662,  0.1752,  0.1553,  0.1203,
          0.0151, -0.1898, -0.1649, -0.1883, -0.0889,  0.1519, -0.0150,  0.0486,
         -0.1481, -0.0758,  0.1683,  0.0613,  0.0195,  0.0416, -0.1855,  0.0541,
         -0.0061],
        [-0.1662,  0.1002, -0.1068,  0.0125,  0.1863, -0.0588, -0.1888, -0.0810,
         -0.0440,  0.0567,  0.0059, -0.0829, -0.0364,  0.1244, -0.1977,  0.0828,
          0.0620,  0.1950, -0.1710,  0.1591, -0.1352,  0.1362, -0.1948, -0.1844,
          0.0895],
        [-0.1993, -0.0306, -0.0635,  0.0707, -0.0932,  0.0730, -0.0831, -0.1581,
         -0.1133, -0.0193, -0.1511,  0.0156,  0.0420,  0.1588,  0.1293,  0.1279,
          0.1491,  0.1205, -0.1197,  0.0915, -0.0688,  0.0237,  0.0973,  0.1628,
         -0.0449]], dtype=torch.float64, requires_grad=True)
Summary AFTER training

==============================================
Summary: 
State	Action	Next State	Reward
0 		 0 		  Q(s,a)=  tensor(3.6393, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 1 		  Q(s,a)=  tensor(2.9529, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 2 		  Q(s,a)=  tensor(3.9924, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 3 		  Q(s,a)=  tensor(3.1811, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 4 		  Q(s,a)=  tensor(3.5461, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 0 		  Q(s,a)=  tensor(3.5823, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 1 		  Q(s,a)=  tensor(2.1243, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 2 		  Q(s,a)=  tensor(2.5386, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 3 		  Q(s,a)=  tensor(2.6308, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 4 		  Q(s,a)=  tensor(2.2772, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 0 		  Q(s,a)=  tensor(2.3820, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 1 		  Q(s,a)=  tensor(4.2785, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 2 		  Q(s,a)=  tensor(2.7737, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 3 		  Q(s,a)=  tensor(4.0118, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 4 		  Q(s,a)=  tensor(3.5065, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 0 		  Q(s,a)=  tensor(3.5711, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 1 		  Q(s,a)=  tensor(1.9342, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 2 		  Q(s,a)=  tensor(2.4234, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 3 		  Q(s,a)=  tensor(2.7278, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 4 		  Q(s,a)=  tensor(2.6168, dtype=torch.float64, grad_fn=<SelectBackward0>)
==============================================

Best trajectory: 
Best trajectory from Test Environment
State:  0.0712  Action:  2  Reward Received:  0
State:  0.6425142857142858  Action:  1  Reward Received:  2.0
State:  0.3440000000000001  Action:  0  Reward Received:  0.1
State:  0.0712  Action:  2  Reward Received:  0
State:  0.6425142857142858  Action:  1  Reward Received:  2.0

Total Reward Received:  4.1
Taking a look at model parameters to see if weights are changing
Parameter containing:
tensor([[ 0.2452,  0.9350,  0.1944, -0.4976, -0.8793, -0.1582,  0.4117, -0.9325,
         -0.2741,  1.1752,  1.3289, -0.0295, -0.6704, -1.0095, -0.2428,  0.6391,
          0.4871, -0.6730,  0.9476,  0.4946, -1.6898, -0.4524,  1.2173,  0.4083,
         -0.7988],
        [-1.1451, -1.2294, -0.9271,  2.0957,  1.7024,  1.1571,  0.2752,  0.5673,
          2.2833, -1.6858, -1.5647,  0.6246,  0.2886,  0.6922,  0.7639, -1.8418,
         -0.2695,  0.1457, -2.0768, -0.3702,  2.1101,  0.8324, -2.2170, -0.7863,
          0.2207],
        [-0.5506, -0.0472, -1.1929,  0.7682,  0.3010,  0.7130,  1.4722, -0.0557,
          1.5998, -0.3239,  1.0481,  0.9025, -1.9397, -0.1690, -0.3489,  0.0550,
         -0.3683, -0.7111, -0.0118,  0.1869, -0.7206,  0.3388, -0.6296,  0.1551,
         -1.5919],
        [-0.8610, -0.5548, -0.6521,  1.4313,  1.2605,  0.6812,  0.2601,  0.2360,
          1.4706, -0.7923, -0.6867,  0.5408, -0.1983,  0.3591,  0.3513, -0.9878,
          0.0767,  0.0371, -1.4305,  0.1205,  0.8862,  0.7109, -1.4942, -0.6669,
          0.0713],
        [-1.0880, -0.4670, -1.3201,  1.4059,  0.7687,  0.9514,  1.2468,  0.0721,
          2.0980, -0.8431,  0.3417,  1.3064, -1.4973,  0.2096,  0.1365, -0.4778,
         -0.1728, -0.3218, -1.0333,  0.0909,  0.1790,  0.6789, -1.1797,  0.0130,
         -1.2358]], dtype=torch.float64, requires_grad=True)
Parameter containing:
tensor([3.0915, 3.0765, 3.4695, 3.0772, 3.0730], dtype=torch.float64,
       requires_grad=True)
Starting Training
layer weights:  Parameter containing:
tensor([[ 0.0676, -0.0802, -0.0916, -0.0536,  0.0745,  0.0428,  0.1033, -0.0969,
         -0.1666, -0.0630, -0.0912,  0.0625,  0.0235,  0.1480, -0.0346, -0.1377,
          0.0874,  0.1641, -0.1595, -0.1770, -0.1237, -0.1449, -0.0907,  0.0347,
          0.0245],
        [-0.0436,  0.1384,  0.1900,  0.0191,  0.0892, -0.1115,  0.0990, -0.1147,
          0.1743, -0.1582,  0.1132, -0.0104, -0.1131,  0.0523,  0.0177,  0.1476,
         -0.1609,  0.1615, -0.0592, -0.0129, -0.0660, -0.0195,  0.1498, -0.0048,
         -0.1527],
        [ 0.0421,  0.1502,  0.1784, -0.0993,  0.0209, -0.1559, -0.0465, -0.1547,
          0.0302,  0.1600, -0.0397,  0.0676,  0.1934,  0.0114, -0.1903, -0.1340,
          0.1619, -0.1586, -0.1708, -0.0485,  0.0247,  0.0216, -0.0731, -0.0878,
         -0.1674],
        [-0.1233,  0.0678, -0.1046,  0.1806, -0.0521, -0.1939, -0.0502,  0.0274,
         -0.0682,  0.0980,  0.1087,  0.0157, -0.1679, -0.1241,  0.1737,  0.1278,
         -0.0017,  0.1151, -0.0204,  0.1490, -0.0590,  0.1278, -0.0385, -0.1385,
          0.1415],
        [ 0.0029,  0.0176, -0.1000, -0.0269,  0.1795, -0.0687, -0.0248,  0.1950,
         -0.0986,  0.1276,  0.1067, -0.1462,  0.1399,  0.1565,  0.1535, -0.0152,
          0.0402,  0.1507, -0.0806, -0.1569,  0.0837,  0.1388, -0.0964,  0.0152,
         -0.1042]], dtype=torch.float64, requires_grad=True)
layer weights:  Parameter containing:
tensor([[ 0.0315,  0.1568, -0.1693, -0.0236, -0.1183, -0.1639, -0.0590,  0.0373,
         -0.0725, -0.0605, -0.1899,  0.0309, -0.0236, -0.1440, -0.0039,  0.1034,
          0.0114, -0.0165, -0.0452,  0.1553,  0.0323,  0.1973, -0.0900, -0.1580,
         -0.0502],
        [-0.0864,  0.1188,  0.0832,  0.0705, -0.0303,  0.0746,  0.0986,  0.1795,
         -0.0027,  0.0331,  0.0107,  0.0242,  0.1012, -0.1111, -0.1667,  0.0949,
          0.0928,  0.0338, -0.1692,  0.1699, -0.1378, -0.1920,  0.0759, -0.1979,
         -0.0358],
        [-0.0944,  0.1719,  0.0224,  0.0867,  0.1061, -0.0093,  0.0895,  0.0345,
          0.1331,  0.1603,  0.0421, -0.1511, -0.0061, -0.1387, -0.0572,  0.0477,
          0.1743,  0.1786, -0.0389, -0.1431, -0.1714, -0.1407, -0.0539,  0.0838,
          0.0322],
        [-0.0547, -0.0561, -0.0651,  0.0260, -0.1051,  0.1487,  0.0957, -0.1537,
         -0.1608,  0.1265, -0.0992,  0.1782,  0.1422,  0.0217, -0.0462, -0.0233,
          0.1695, -0.0133,  0.1629,  0.1330, -0.0059, -0.1050,  0.1374, -0.0716,
         -0.1737],
        [-0.1908, -0.1996, -0.1441, -0.1433, -0.0127, -0.1621,  0.1150, -0.1320,
         -0.0155, -0.1589, -0.1422, -0.1912,  0.1009, -0.0148,  0.0947, -0.0563,
          0.1704,  0.1090, -0.0457,  0.0922, -0.0837, -0.1188, -0.1352,  0.1352,
         -0.1129]], dtype=torch.float64, requires_grad=True)
Summary AFTER training

==============================================
Summary: 
State	Action	Next State	Reward
0 		 0 		  Q(s,a)=  tensor(3.8055, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 1 		  Q(s,a)=  tensor(3.1249, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 2 		  Q(s,a)=  tensor(4.6478, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 3 		  Q(s,a)=  tensor(2.6769, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 4 		  Q(s,a)=  tensor(3.7281, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 0 		  Q(s,a)=  tensor(3.6825, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 1 		  Q(s,a)=  tensor(2.5966, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 2 		  Q(s,a)=  tensor(3.3148, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 3 		  Q(s,a)=  tensor(1.8553, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 4 		  Q(s,a)=  tensor(2.4061, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 0 		  Q(s,a)=  tensor(2.1298, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 1 		  Q(s,a)=  tensor(4.7413, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 2 		  Q(s,a)=  tensor(3.7554, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 3 		  Q(s,a)=  tensor(2.7804, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 4 		  Q(s,a)=  tensor(3.5982, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 0 		  Q(s,a)=  tensor(2.8878, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 1 		  Q(s,a)=  tensor(2.6784, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 2 		  Q(s,a)=  tensor(3.5679, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 3 		  Q(s,a)=  tensor(1.0327, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 4 		  Q(s,a)=  tensor(2.4361, dtype=torch.float64, grad_fn=<SelectBackward0>)
==============================================

Best trajectory: 
Best trajectory from Test Environment
State:  0.08045714285714287  Action:  2  Reward Received:  0
State:  0.644  Action:  1  Reward Received:  2.0
State:  0.35074285714285713  Action:  0  Reward Received:  0.1
State:  0.08045714285714287  Action:  2  Reward Received:  0
State:  0.644  Action:  1  Reward Received:  2.0

Total Reward Received:  4.1
Taking a look at model parameters to see if weights are changing
Parameter containing:
tensor([[ 1.7650, -1.3279, -0.7059,  1.2773,  0.6435, -0.7172, -1.1119,  0.1118,
         -0.3772, -0.2821,  1.3216, -1.6587,  0.5941, -0.4566,  0.2275,  0.2846,
          0.1173, -0.1187, -0.6811, -2.0245,  0.7150,  1.1976,  0.4207,  0.2821,
         -1.0033],
        [-3.3664,  2.4005,  1.0027, -2.2120, -0.7026,  0.8614,  1.8710,  0.9150,
          1.2552,  0.8528, -3.1031,  2.1553, -0.7692,  0.8023, -1.1156,  0.2351,
          0.4285, -0.8274,  0.7676,  3.1400, -2.0388, -2.3805, -0.4900, -0.5169,
          1.4272],
        [-0.2845, -1.6664,  0.2895, -0.3474,  0.3807,  0.3969,  1.2169,  0.1029,
          0.1959,  1.1836, -0.0331, -1.4394, -0.0389,  0.6410, -0.9409, -0.0080,
          0.4110, -1.8548,  0.2126, -0.6005,  0.1279, -1.6575,  1.2923,  0.5824,
          0.9149],
        [-2.1918,  1.2942,  0.4412, -1.4750, -0.5512,  0.5579,  1.1557,  0.3053,
          0.6215,  0.6093, -2.1515,  1.3941, -0.4650,  0.5579, -0.7646,  0.0240,
          0.3470, -0.7189,  0.6677,  1.9120, -1.3272, -1.5804, -0.2664, -0.3124,
          0.6723],
        [-1.7454, -0.4626,  0.5178, -1.4627, -0.1479,  0.5580,  1.8058,  0.1946,
          0.5658,  0.9682, -1.5110, -0.0306, -0.3041,  0.9828, -0.8970, -0.0481,
          0.4818, -1.6573,  0.6294,  1.2770, -0.6078, -2.1707,  0.6054,  0.3519,
          1.2693]], dtype=torch.float64, requires_grad=True)
Parameter containing:
tensor([3.7652, 2.9683, 4.1007, 2.6919, 3.3536], dtype=torch.float64,
       requires_grad=True)
Starting Training
layer weights:  Parameter containing:
tensor([[-0.0779,  0.0488, -0.1493, -0.0512,  0.1150, -0.1689, -0.0560, -0.1562,
         -0.1578, -0.0528, -0.1717, -0.0521, -0.1372,  0.0593,  0.1960, -0.1977,
         -0.0241,  0.0210,  0.0092,  0.1957, -0.1974,  0.0525,  0.0703,  0.0691,
          0.1065],
        [-0.0245,  0.1189,  0.0236,  0.1945, -0.1056, -0.0506,  0.0456,  0.0599,
          0.1148,  0.0497,  0.1808,  0.0515, -0.1160, -0.1151,  0.1097, -0.0885,
         -0.1056, -0.0764,  0.0131, -0.1711,  0.1559,  0.0629,  0.0359,  0.0249,
         -0.0023],
        [-0.0439,  0.1431,  0.0713,  0.1095, -0.1026, -0.1249,  0.0318,  0.0628,
         -0.0461, -0.0814,  0.0166,  0.0056,  0.1846, -0.0583,  0.1295, -0.1824,
          0.1276,  0.0005,  0.0926, -0.0962,  0.1586, -0.0995,  0.0231, -0.1888,
         -0.0073],
        [-0.1345,  0.1901,  0.1291, -0.1554, -0.0025,  0.0977,  0.1909, -0.0290,
          0.0238,  0.1437, -0.1376,  0.1117,  0.0177, -0.0296,  0.0728,  0.1748,
          0.1453, -0.1409,  0.1769, -0.0139,  0.1673,  0.1453, -0.0383,  0.0137,
          0.0601],
        [ 0.1758,  0.1526,  0.0709,  0.1149,  0.1790, -0.0960,  0.0665, -0.1187,
         -0.0451, -0.1617, -0.0560, -0.0708, -0.1379, -0.0924,  0.1122, -0.1689,
         -0.0195,  0.0546,  0.2000, -0.0795,  0.1612, -0.0328, -0.1591,  0.1891,
          0.1587]], dtype=torch.float64, requires_grad=True)
layer weights:  Parameter containing:
tensor([[ 0.0494,  0.1523, -0.0149,  0.0839, -0.1636,  0.0274, -0.0426, -0.0026,
         -0.0477,  0.0076,  0.0015,  0.0870,  0.1257, -0.0952,  0.1633,  0.1909,
          0.0529,  0.1396,  0.1121,  0.0065,  0.1151,  0.0133, -0.1948, -0.1996,
         -0.0309],
        [ 0.0373,  0.0916,  0.0851, -0.0050, -0.1350, -0.0817, -0.0449, -0.0922,
         -0.1400, -0.1590, -0.1333, -0.1603, -0.1002,  0.1586, -0.1254,  0.1364,
         -0.0359, -0.1267, -0.0685, -0.0623,  0.0310,  0.1681, -0.0532, -0.1925,
         -0.1811],
        [-0.1430,  0.1758,  0.0246, -0.0087, -0.1591,  0.1549, -0.0769,  0.1532,
          0.1952, -0.1739, -0.1867,  0.1524, -0.1365,  0.1986,  0.0601,  0.1796,
          0.0531,  0.1068,  0.0283,  0.1257,  0.1079, -0.1472, -0.1630, -0.0759,
          0.1800],
        [ 0.1608,  0.0573, -0.1840, -0.1016,  0.0732,  0.1868,  0.1245, -0.1161,
          0.0945, -0.0395, -0.1177,  0.1450,  0.0420,  0.0613,  0.0117, -0.1092,
         -0.1595, -0.1776,  0.1414, -0.0301,  0.0296,  0.1316,  0.0134, -0.0245,
          0.1953],
        [ 0.1753,  0.1364, -0.1465, -0.0202,  0.0636,  0.0540, -0.1146,  0.1383,
          0.1869, -0.0491,  0.1510, -0.0266,  0.0416, -0.1317,  0.1985,  0.0345,
         -0.0106,  0.1810,  0.1010, -0.1478, -0.1575,  0.1269, -0.1994, -0.1390,
         -0.1848]], dtype=torch.float64, requires_grad=True)
Summary AFTER training

==============================================
Summary: 
State	Action	Next State	Reward
0 		 0 		  Q(s,a)=  tensor(4.3324, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 1 		  Q(s,a)=  tensor(3.1379, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 2 		  Q(s,a)=  tensor(4.4457, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 3 		  Q(s,a)=  tensor(2.8683, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 4 		  Q(s,a)=  tensor(4.4311, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 0 		  Q(s,a)=  tensor(4.1117, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 1 		  Q(s,a)=  tensor(2.5560, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 2 		  Q(s,a)=  tensor(2.9445, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 3 		  Q(s,a)=  tensor(2.0881, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 4 		  Q(s,a)=  tensor(2.9590, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 0 		  Q(s,a)=  tensor(3.0041, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 1 		  Q(s,a)=  tensor(5.1734, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 2 		  Q(s,a)=  tensor(3.3011, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 3 		  Q(s,a)=  tensor(3.2001, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 4 		  Q(s,a)=  tensor(4.1567, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 0 		  Q(s,a)=  tensor(3.6933, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 1 		  Q(s,a)=  tensor(3.0813, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 2 		  Q(s,a)=  tensor(3.3421, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 3 		  Q(s,a)=  tensor(1.8002, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 4 		  Q(s,a)=  tensor(3.0139, dtype=torch.float64, grad_fn=<SelectBackward0>)
==============================================

Best trajectory: 
Best trajectory from Test Environment
State:  0.05234285714285715  Action:  2  Reward Received:  0
State:  0.6395428571428571  Action:  1  Reward Received:  2.0
State:  0.3532571428571428  Action:  0  Reward Received:  0.1
State:  0.05234285714285715  Action:  2  Reward Received:  0
State:  0.6395428571428571  Action:  1  Reward Received:  2.0

Total Reward Received:  4.1
Taking a look at model parameters to see if weights are changing
Parameter containing:
tensor([[-0.5997,  0.5624,  0.2472,  0.2789, -0.3067,  0.6371, -0.8821,  0.1653,
          0.1750, -0.0390, -0.6096, -0.9494, -0.9724, -1.0960,  0.5226,  1.2855,
          1.2319,  1.0096,  0.3898,  0.0950,  0.2597,  0.6985, -1.2297,  0.1506,
         -1.5036],
        [ 0.5676, -0.6739, -1.8501, -0.1812, -0.8714, -0.3072,  2.1376, -0.7425,
         -1.8421, -1.9300,  1.3375,  3.5919,  3.5037,  2.8177, -1.3233, -1.0662,
         -1.2898, -2.2537, -0.8343,  1.1343, -0.3965, -1.1492,  2.1825, -2.3362,
          2.2457],
        [-1.0836, -0.2771, -0.1025, -0.6357, -1.9487,  0.4343,  0.3404,  0.0784,
          0.2404, -2.4856,  0.1626,  0.9311,  0.9659,  0.7242,  0.4062,  0.6384,
          2.5209, -0.0969, -0.2181,  0.8360, -0.5160, -0.5682,  0.5648, -0.0549,
         -1.9447],
        [ 0.1441, -0.4208, -1.3032, -0.3135, -0.6606,  0.1392,  1.1664, -0.5297,
         -0.8815, -1.3961,  0.5587,  2.0825,  1.9221,  1.3546, -0.6198, -0.5872,
         -0.4096, -1.2970, -0.3367,  0.6711, -0.3318, -0.5978,  1.0841, -1.2255,
          0.9456],
        [-0.2290, -0.5762, -1.1716, -0.5737, -1.5237,  0.0781,  1.1412, -0.2562,
         -0.6152, -2.4736,  1.0294,  2.2024,  2.4044,  1.4177, -0.1731, -0.2832,
          0.9806, -1.0043, -0.4654,  0.8318, -0.8201, -0.8289,  1.2790, -1.1650,
         -0.4706]], dtype=torch.float64, requires_grad=True)
Parameter containing:
tensor([3.9456, 3.0413, 3.9676, 2.7788, 4.1491], dtype=torch.float64,
       requires_grad=True)
Starting Training
layer weights:  Parameter containing:
tensor([[ 0.0017,  0.1348,  0.0032,  0.0644, -0.1663, -0.1885,  0.0939, -0.1233,
          0.0093, -0.1241,  0.0363, -0.0553,  0.1092, -0.1700, -0.1549, -0.0392,
          0.0775, -0.0141,  0.0299, -0.0517,  0.1234,  0.1676,  0.0053, -0.0247,
         -0.1008],
        [-0.1558, -0.0957,  0.0494, -0.1651,  0.0068, -0.1876, -0.1092, -0.1213,
          0.0423, -0.0642,  0.0312,  0.1183, -0.1544, -0.0533,  0.1604,  0.0268,
         -0.0467,  0.0493, -0.0870, -0.0426,  0.0782, -0.1967,  0.0413,  0.0208,
         -0.1749],
        [ 0.0212,  0.0223,  0.0849,  0.0716,  0.0419, -0.1816, -0.0591,  0.0536,
         -0.0330,  0.0095, -0.1336, -0.0762, -0.1070,  0.0751, -0.1609,  0.1882,
         -0.0424,  0.0092,  0.0322, -0.1950, -0.1128,  0.0256, -0.1264,  0.1937,
          0.0945],
        [ 0.0589,  0.1583,  0.0900,  0.0578,  0.0669,  0.0779,  0.0327,  0.0182,
         -0.1394,  0.1783,  0.1446,  0.1729,  0.0313,  0.1556,  0.1003,  0.0468,
          0.0467, -0.1329, -0.1483,  0.1192,  0.0433,  0.1441,  0.1901,  0.1934,
          0.0792],
        [ 0.1341,  0.1221, -0.1675,  0.0793,  0.1619, -0.1030,  0.0414,  0.1609,
         -0.1059, -0.1699,  0.0264,  0.0279,  0.0483,  0.0583, -0.0469,  0.1821,
          0.0259,  0.1535, -0.1170,  0.0116,  0.1809,  0.1183, -0.1358, -0.1182,
         -0.1321]], dtype=torch.float64, requires_grad=True)
layer weights:  Parameter containing:
tensor([[-1.1118e-01,  1.0314e-01,  1.8242e-01,  1.4507e-02, -1.4716e-01,
          1.7504e-01,  7.2700e-02,  9.4776e-02,  1.3003e-01,  6.4547e-02,
          2.3034e-02,  8.2684e-02, -1.2279e-01,  5.7725e-02, -1.8445e-01,
         -5.1357e-02,  1.1120e-03, -8.0166e-02, -2.4436e-02,  5.4268e-03,
         -2.3529e-02,  8.0449e-02, -1.3204e-01,  1.0998e-01, -1.9656e-01],
        [ 1.0038e-01, -6.1251e-02, -1.0706e-01, -8.6929e-03,  1.1414e-02,
          2.3072e-02,  5.3527e-03,  9.3163e-02, -1.0365e-01, -1.4519e-01,
          1.7802e-01, -1.0743e-01,  1.9804e-01, -1.3653e-01, -6.0893e-02,
          9.9348e-03, -1.9216e-01, -2.8749e-02, -1.5984e-01,  6.2994e-03,
          1.2716e-01,  9.7580e-02, -1.2941e-04, -9.4249e-03, -1.1861e-01],
        [ 7.7557e-02, -3.2579e-02,  9.0464e-02,  1.8244e-01,  2.4097e-02,
          1.5575e-01, -1.2787e-02, -1.3819e-01, -1.7329e-01, -9.5289e-02,
         -1.0383e-01, -1.9310e-01, -1.6876e-01,  1.8253e-01, -8.8736e-02,
         -8.3752e-02, -2.6571e-02, -1.2834e-01, -1.8468e-01, -6.7507e-02,
          7.1474e-02, -1.6755e-02, -1.8248e-01, -1.7788e-01, -1.7075e-01],
        [-6.1797e-02, -1.0004e-01, -9.3333e-03,  1.4951e-01, -6.3114e-03,
          6.2785e-02, -9.8207e-02, -9.4099e-02, -5.1312e-02, -5.1515e-04,
          1.5329e-01, -1.9712e-01, -1.2001e-01, -1.7779e-01, -5.4219e-02,
         -1.2917e-01,  4.7434e-02, -1.2851e-01,  1.0805e-01,  5.6682e-04,
         -1.8806e-01, -1.9517e-01,  1.0647e-02, -1.9649e-01,  1.7668e-01],
        [-1.0688e-01,  1.4547e-01,  1.6996e-01, -1.3776e-01, -1.3856e-01,
         -1.1095e-02, -1.5643e-01, -2.3155e-02, -5.3033e-02,  1.9091e-01,
          2.5642e-02, -1.9196e-01,  7.0308e-02, -1.5342e-01,  7.3741e-02,
          1.6535e-01,  1.9898e-01, -1.6316e-01,  2.0865e-03,  1.5441e-01,
         -1.9992e-01,  1.7708e-01,  1.4301e-01,  1.7354e-01, -1.7675e-01]],
       dtype=torch.float64, requires_grad=True)
Summary AFTER training

==============================================
Summary: 
State	Action	Next State	Reward
0 		 0 		  Q(s,a)=  tensor(4.1086, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 1 		  Q(s,a)=  tensor(3.4097, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 2 		  Q(s,a)=  tensor(4.7674, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 3 		  Q(s,a)=  tensor(3.4112, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 4 		  Q(s,a)=  tensor(4.2030, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 0 		  Q(s,a)=  tensor(4.0480, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 1 		  Q(s,a)=  tensor(2.7788, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 2 		  Q(s,a)=  tensor(3.6270, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 3 		  Q(s,a)=  tensor(2.5203, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 4 		  Q(s,a)=  tensor(2.8213, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 0 		  Q(s,a)=  tensor(2.3366, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 1 		  Q(s,a)=  tensor(5.0646, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 2 		  Q(s,a)=  tensor(4.2482, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 3 		  Q(s,a)=  tensor(3.7592, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 4 		  Q(s,a)=  tensor(3.5982, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 0 		  Q(s,a)=  tensor(3.4586, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 1 		  Q(s,a)=  tensor(2.9554, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 2 		  Q(s,a)=  tensor(4.2829, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 3 		  Q(s,a)=  tensor(2.4450, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 4 		  Q(s,a)=  tensor(2.6002, dtype=torch.float64, grad_fn=<SelectBackward0>)
==============================================

Best trajectory: 
Best trajectory from Test Environment
State:  0.07565714285714285  Action:  2  Reward Received:  0
State:  0.6590857142857144  Action:  1  Reward Received:  2.0
State:  0.3538285714285714  Action:  0  Reward Received:  0.1
State:  0.07565714285714285  Action:  2  Reward Received:  0
State:  0.6590857142857144  Action:  1  Reward Received:  2.0

Total Reward Received:  4.1
Taking a look at model parameters to see if weights are changing
Parameter containing:
tensor([[ 1.3887,  0.2201, -0.0918, -1.1740,  0.9283,  2.4904, -0.5826,  0.0269,
          0.2033, -0.6477,  1.3960, -1.7028, -1.5420,  1.4090, -1.3596, -1.3988,
         -0.4998, -0.0393, -1.1586,  1.5371,  1.2483, -0.5842, -0.5918, -0.2536,
         -0.5691],
        [-2.0613, -1.1448,  0.3090,  0.9805, -0.8213, -2.9039,  1.0985,  1.1884,
         -0.8812,  0.8144, -3.0996,  2.2506,  2.2633, -2.3767,  1.2125,  2.8180,
          0.8975,  0.2728,  2.0407, -2.3430, -2.5091,  0.7209,  1.2082,  0.4473,
          0.6741],
        [ 0.2546, -1.6267,  0.4744, -1.2869,  0.5784,  0.0958,  0.7789, -0.1100,
         -1.1083, -0.2585, -1.8916,  0.4119, -0.2594, -0.6481, -0.3071,  1.0230,
          0.3658,  0.4692,  1.4777,  0.8113, -0.0334,  0.0984,  0.3636, -0.2532,
          0.8066],
        [-1.1622, -1.1714,  0.3198,  0.2224, -0.3010, -1.5330,  0.7163,  0.4666,
         -0.7554,  0.4505, -2.1234,  1.2487,  0.9517, -1.6362,  0.5566,  1.7029,
          0.7330,  0.1998,  1.7773, -0.9740, -1.6033,  0.1683,  0.8048,  0.0124,
          0.8863],
        [-0.6599, -1.3805,  0.4705, -1.0088, -0.0820, -0.9774,  0.6174,  0.1341,
         -1.0145,  0.2386, -2.2397,  0.8025,  0.4646, -1.4696,  0.1885,  1.5869,
          0.6668,  0.2467,  1.6813,  0.0734, -1.0546,  0.3557,  0.7463,  0.1506,
          0.6480]], dtype=torch.float64, requires_grad=True)
Parameter containing:
tensor([3.9823, 3.1970, 4.1087, 3.1430, 3.7845], dtype=torch.float64,
       requires_grad=True)
Starting Training
layer weights:  Parameter containing:
tensor([[-0.0246,  0.1007, -0.1612, -0.1850, -0.0093,  0.1738,  0.0711,  0.0637,
          0.0515, -0.0330,  0.1671, -0.0339,  0.0332,  0.0391,  0.0235, -0.0856,
          0.1119, -0.1879,  0.1834,  0.0021, -0.1613, -0.1562, -0.1732, -0.1919,
         -0.0113],
        [-0.0155, -0.0503,  0.0232,  0.0012,  0.0109,  0.1693, -0.0214,  0.0500,
         -0.1857,  0.1802,  0.1373,  0.0316, -0.1352, -0.0926,  0.1420, -0.0138,
         -0.0641,  0.0670,  0.1211,  0.0641,  0.1112,  0.1699,  0.0496,  0.1586,
         -0.1222],
        [-0.1929, -0.1291, -0.0375,  0.0221, -0.0720, -0.1737, -0.0452, -0.1855,
         -0.0927,  0.0555, -0.1494, -0.0841, -0.0854,  0.1762,  0.1623,  0.1822,
         -0.0579, -0.1326,  0.1406, -0.1947,  0.0601, -0.0465, -0.1620,  0.1335,
          0.1054],
        [-0.0529, -0.1062,  0.1830, -0.1286, -0.1642,  0.1962, -0.1077,  0.1723,
          0.0536, -0.0184, -0.0752,  0.1903, -0.1850,  0.1741, -0.0376,  0.0729,
          0.1447, -0.1396, -0.0508, -0.1282, -0.1486,  0.0228,  0.0767,  0.1975,
         -0.1074],
        [ 0.0990, -0.0839, -0.0493, -0.1595, -0.1939, -0.0916, -0.0195,  0.0059,
          0.1776, -0.1619, -0.0715,  0.1171, -0.1027, -0.1284,  0.1753, -0.1820,
         -0.0644,  0.1587, -0.0589,  0.1895, -0.0590,  0.1410,  0.1381,  0.1114,
          0.0558]], dtype=torch.float64, requires_grad=True)
layer weights:  Parameter containing:
tensor([[-0.0239, -0.1447,  0.0151, -0.0759, -0.0561,  0.1628,  0.1820, -0.0014,
          0.1676, -0.1912, -0.1953, -0.1130,  0.0711, -0.1793,  0.0210, -0.1227,
         -0.0238, -0.1038, -0.1003,  0.1357,  0.1759,  0.1775, -0.1701,  0.1329,
          0.0821],
        [-0.0175, -0.1949, -0.0410, -0.1170, -0.1763,  0.0201,  0.1709,  0.1195,
         -0.0500, -0.1596,  0.0428, -0.0351, -0.0789,  0.1772,  0.0855,  0.0020,
          0.1480,  0.0679,  0.0773, -0.0178, -0.1684, -0.1686, -0.1396,  0.0871,
          0.1430],
        [ 0.0161,  0.1706,  0.1369, -0.1337, -0.0098,  0.0543,  0.1466,  0.0533,
         -0.0478,  0.1515, -0.1484,  0.1950,  0.1761,  0.0900, -0.0604,  0.1152,
          0.1361,  0.1815,  0.1390, -0.0010, -0.0153, -0.0395, -0.0208,  0.1226,
          0.1286],
        [ 0.1647, -0.1219,  0.0751, -0.1490,  0.1850,  0.1341,  0.0126, -0.1840,
         -0.0723,  0.0603, -0.0169,  0.0273, -0.0032, -0.0974, -0.1101,  0.1678,
         -0.1450,  0.0570, -0.1911,  0.1178, -0.1302,  0.1418,  0.1152, -0.0016,
         -0.0603],
        [ 0.1045, -0.1427,  0.0163, -0.0076, -0.1042,  0.0720,  0.0915,  0.1920,
          0.1066,  0.0521,  0.0115, -0.0250,  0.1491,  0.1225,  0.1113, -0.0423,
         -0.1029, -0.0306, -0.0646, -0.0034, -0.0260,  0.0087, -0.1107,  0.1512,
          0.1803]], dtype=torch.float64, requires_grad=True)
Summary AFTER training

==============================================
Summary: 
State	Action	Next State	Reward
0 		 0 		  Q(s,a)=  tensor(4.0385, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 1 		  Q(s,a)=  tensor(3.2253, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 2 		  Q(s,a)=  tensor(4.4006, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 3 		  Q(s,a)=  tensor(3.1685, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 4 		  Q(s,a)=  tensor(3.9510, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 0 		  Q(s,a)=  tensor(4.0274, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 1 		  Q(s,a)=  tensor(2.4589, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 2 		  Q(s,a)=  tensor(2.7477, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 3 		  Q(s,a)=  tensor(2.6970, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 4 		  Q(s,a)=  tensor(2.0811, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 0 		  Q(s,a)=  tensor(2.8255, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 1 		  Q(s,a)=  tensor(4.6092, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 2 		  Q(s,a)=  tensor(3.0748, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 3 		  Q(s,a)=  tensor(3.8586, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 4 		  Q(s,a)=  tensor(2.8086, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 0 		  Q(s,a)=  tensor(3.7672, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 1 		  Q(s,a)=  tensor(2.3429, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 2 		  Q(s,a)=  tensor(2.4367, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 3 		  Q(s,a)=  tensor(2.4539, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 4 		  Q(s,a)=  tensor(1.4317, dtype=torch.float64, grad_fn=<SelectBackward0>)
==============================================

Best trajectory: 
Best trajectory from Test Environment
State:  0.06662857142857143  Action:  2  Reward Received:  0
State:  0.6314285714285715  Action:  1  Reward Received:  2.0
State:  0.3592  Action:  0  Reward Received:  0.1
State:  0.06662857142857143  Action:  2  Reward Received:  0
State:  0.6314285714285715  Action:  1  Reward Received:  2.0

Total Reward Received:  4.1
Taking a look at model parameters to see if weights are changing
Parameter containing:
tensor([[-1.9629e-01,  2.2203e-01, -1.9795e-01, -1.2570e-01, -1.3759e+00,
          1.5181e+00, -1.9570e+00,  3.1734e-01,  4.8472e-02, -9.6566e-01,
         -4.8674e-02, -6.4286e-01,  7.8126e-01, -6.5730e-01,  1.4217e+00,
         -3.3605e-01,  4.7268e-01, -6.6739e-01,  1.3324e+00,  8.4535e-01,
          9.8143e-01, -8.3544e-01, -1.9814e+00,  8.9469e-01,  9.5220e-01],
        [ 6.3307e-01, -5.9270e-01,  3.0793e-01, -2.2495e-01,  1.7764e+00,
         -2.9133e+00,  5.0686e+00, -7.0986e-01,  3.5659e-01,  8.9934e-01,
         -1.5581e+00,  2.2806e-01, -1.5682e+00,  1.1599e+00, -2.8579e+00,
          1.2213e+00, -7.7138e-01,  3.4505e-01, -1.4215e+00, -1.9781e+00,
         -8.6007e-01,  3.1496e+00,  2.4868e+00, -1.5874e+00, -4.7620e-01],
        [-5.7262e-01,  5.7137e-01,  8.0667e-02, -2.6511e-01, -1.6105e+00,
         -8.3739e-01,  1.4920e+00, -9.9977e-01,  6.2159e-01,  5.6781e-01,
         -1.2712e+00, -1.4880e+00, -7.0398e-01,  2.6682e-01, -1.1867e+00,
          4.5802e-01,  5.2139e-01,  5.6253e-01,  1.1079e-01,  6.4390e-01,
          1.0484e-01,  7.8552e-01, -6.0813e-01,  4.4070e-01,  1.1042e+00],
        [ 5.5805e-01, -3.3084e-01,  2.3920e-01, -2.4939e-01,  1.1955e+00,
         -1.4955e+00,  2.7459e+00, -6.4739e-01,  1.3270e-01,  5.5116e-01,
         -1.0371e+00,  1.0596e-01, -8.1894e-01,  4.2084e-01, -1.7251e+00,
          9.0651e-01, -6.7322e-01,  7.5763e-02, -8.5750e-01, -1.0688e+00,
         -4.1758e-01,  2.0880e+00,  1.4308e+00, -9.7179e-01, -3.1044e-01],
        [-3.1547e-01,  8.3243e-02,  7.5825e-02, -1.2935e-01, -9.8086e-01,
         -1.5645e+00,  2.6699e+00, -1.0180e+00,  8.3202e-01,  8.0722e-01,
         -1.3084e+00, -1.4434e+00, -1.0974e+00,  5.6628e-01, -1.7697e+00,
          5.2318e-01, -2.7337e-03,  5.1754e-01, -7.0659e-01,  1.2846e-01,
         -2.3065e-01,  1.5663e+00,  2.1805e-01,  7.5408e-03,  7.8587e-01]],
       dtype=torch.float64, requires_grad=True)
Parameter containing:
tensor([3.7721, 3.0457, 3.9167, 3.0594, 3.5779], dtype=torch.float64,
       requires_grad=True)
Starting Training
layer weights:  Parameter containing:
tensor([[-0.1888, -0.1252,  0.0112, -0.0825,  0.1572,  0.0299, -0.1936, -0.0884,
          0.1067,  0.1745,  0.0396,  0.1799, -0.1942,  0.1159,  0.1445,  0.1782,
         -0.0370,  0.1848, -0.1795,  0.0755, -0.0206, -0.0873, -0.0412, -0.0499,
         -0.0186],
        [ 0.0909, -0.0489, -0.0768,  0.0041,  0.1292, -0.1524,  0.0607, -0.0315,
          0.1809, -0.0514, -0.0043,  0.1751,  0.0842, -0.0155, -0.0721,  0.0976,
         -0.0825,  0.1230,  0.1903, -0.1049, -0.1287, -0.1263,  0.0536,  0.1884,
          0.0270],
        [ 0.1964,  0.1579,  0.0215,  0.1278, -0.0153,  0.0759,  0.1790, -0.1414,
         -0.0444,  0.1635, -0.1690, -0.1154,  0.0610, -0.1143, -0.1047, -0.1792,
         -0.1102,  0.1930, -0.0148,  0.0339,  0.1903, -0.0890, -0.0250, -0.0729,
          0.1787],
        [-0.1056, -0.1391,  0.0591, -0.1321, -0.1679, -0.0870, -0.0475, -0.0139,
          0.0590, -0.1906,  0.1902, -0.0185, -0.1810,  0.0898, -0.0176, -0.1401,
          0.0377,  0.1002, -0.0391,  0.1904,  0.0752,  0.1974, -0.1879,  0.1175,
          0.0035],
        [ 0.1931, -0.1181, -0.1788,  0.0977, -0.1912,  0.0357, -0.1350,  0.0648,
         -0.1932,  0.0418,  0.0885, -0.1729, -0.0879,  0.1593, -0.0379,  0.1163,
         -0.1226, -0.1853,  0.0246, -0.0199, -0.0119,  0.1432, -0.1732,  0.1340,
         -0.0336]], dtype=torch.float64, requires_grad=True)
layer weights:  Parameter containing:
tensor([[-8.6826e-02, -2.2508e-02,  9.0370e-02, -1.3699e-01,  1.7337e-01,
          1.0331e-01, -1.5514e-01, -1.1484e-01, -9.6927e-02, -1.9288e-02,
         -1.6410e-02,  1.8402e-01, -1.9442e-01,  2.7502e-04, -3.0487e-02,
         -1.4910e-01,  1.5071e-02, -9.4193e-02, -1.8660e-01,  1.5735e-02,
          1.9668e-01,  1.7386e-02,  1.2754e-01,  5.6892e-02, -1.6060e-01],
        [-8.3875e-02,  9.2985e-02, -4.4508e-03, -1.3624e-02, -1.6717e-01,
          6.8047e-02,  1.6822e-01,  4.7379e-02,  1.7886e-01, -1.3274e-01,
         -1.2018e-01,  1.0024e-03, -7.4734e-02,  1.9369e-01, -1.6827e-01,
          4.9112e-02, -9.7423e-02,  5.5132e-02,  8.3887e-02,  7.0952e-02,
          1.3279e-01,  1.2051e-01, -3.8976e-02,  4.7889e-02,  1.0466e-01],
        [-1.3138e-01, -1.1894e-01, -8.9869e-02, -1.9321e-01,  1.9876e-01,
         -1.7234e-01, -1.9723e-01,  1.8163e-01,  7.1890e-02,  1.1597e-01,
          2.7807e-02, -1.4405e-01, -1.9600e-01, -8.1996e-02, -3.0573e-02,
          2.7833e-02, -1.0438e-01, -6.1855e-02, -1.0349e-01, -4.0997e-02,
         -1.6652e-01,  1.2906e-01,  1.4488e-01,  1.2191e-01, -1.5693e-01],
        [ 2.4518e-02,  1.9138e-01,  1.0717e-01, -1.7323e-01, -9.8767e-02,
         -6.1613e-03, -5.8083e-02,  8.3750e-02,  8.7493e-02,  2.0875e-02,
         -1.8233e-02,  8.2004e-03,  6.6310e-02, -1.3077e-01, -2.1577e-05,
          4.3918e-02,  1.0546e-01, -2.9621e-02,  9.3000e-04, -3.4625e-02,
         -1.4265e-01,  8.6041e-02, -1.2733e-01,  1.9344e-01, -1.6469e-01],
        [ 1.1899e-01,  1.5014e-01, -2.2707e-02, -3.0105e-03,  6.1730e-02,
         -3.4252e-03,  1.3847e-01,  1.0458e-01,  1.4053e-01,  1.7799e-01,
          8.6767e-02,  1.5601e-01,  1.2211e-01, -1.1071e-01, -7.8418e-03,
          9.5802e-02,  1.6861e-01, -3.7611e-04,  1.7508e-01,  1.3564e-01,
          1.8666e-03,  1.8583e-02, -1.9356e-01,  1.3396e-01,  8.8147e-02]],
       dtype=torch.float64, requires_grad=True)
Summary AFTER training

==============================================
Summary: 
State	Action	Next State	Reward
0 		 0 		  Q(s,a)=  tensor(4.0567, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 1 		  Q(s,a)=  tensor(3.2864, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 2 		  Q(s,a)=  tensor(4.9564, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 3 		  Q(s,a)=  tensor(2.8338, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 4 		  Q(s,a)=  tensor(3.8429, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 0 		  Q(s,a)=  tensor(4.1763, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 1 		  Q(s,a)=  tensor(2.5825, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 2 		  Q(s,a)=  tensor(3.2000, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 3 		  Q(s,a)=  tensor(1.8854, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 4 		  Q(s,a)=  tensor(2.4959, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 0 		  Q(s,a)=  tensor(3.2228, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 1 		  Q(s,a)=  tensor(4.8004, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 2 		  Q(s,a)=  tensor(3.3651, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 3 		  Q(s,a)=  tensor(2.9340, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 4 		  Q(s,a)=  tensor(4.0456, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 0 		  Q(s,a)=  tensor(3.9522, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 1 		  Q(s,a)=  tensor(2.5498, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 2 		  Q(s,a)=  tensor(3.1539, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 3 		  Q(s,a)=  tensor(1.4611, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 4 		  Q(s,a)=  tensor(2.9501, dtype=torch.float64, grad_fn=<SelectBackward0>)
==============================================

Best trajectory: 
Best trajectory from Test Environment
State:  0.0710857142857143  Action:  2  Reward Received:  0
State:  0.6420571428571429  Action:  1  Reward Received:  2.0
State:  0.36651428571428574  Action:  0  Reward Received:  0.1
State:  0.0710857142857143  Action:  2  Reward Received:  0
State:  0.6420571428571429  Action:  1  Reward Received:  2.0

Total Reward Received:  4.1
Taking a look at model parameters to see if weights are changing
Parameter containing:
tensor([[-1.3846e+00, -4.3897e-01,  2.8085e-02,  4.8446e-01,  1.0094e+00,
          3.3525e-01,  1.1367e+00,  1.9559e-01, -4.7263e-01, -4.3694e-01,
         -9.2149e-01, -3.6215e-01, -6.7836e-01,  8.3205e-01, -1.2489e-01,
          1.0783e+00, -2.7617e-01,  4.5029e-01, -2.6699e-02, -2.0710e-01,
          6.0457e-02, -1.5611e+00,  2.7030e-01,  1.0639e+00, -4.5235e-01],
        [ 2.1871e+00,  5.1173e-01, -1.8810e-01, -1.3438e+00, -2.4618e+00,
         -9.2993e-01, -2.8436e+00,  4.7208e-02,  5.5907e-02,  2.5560e+00,
          2.1538e+00,  1.3577e+00, -1.4302e-01, -3.8382e-01,  1.4301e-01,
         -2.7970e+00,  9.4946e-01, -1.7500e+00,  1.2930e+00,  9.0468e-01,
          2.7944e-01,  3.8326e+00,  6.9662e-01, -3.5247e+00,  3.7827e-01],
        [ 1.5884e-01, -2.1764e-01, -5.0621e-01,  9.5348e-01, -8.9184e-01,
          6.8962e-01,  4.3192e-01, -3.5144e-01,  4.8661e-01,  3.1034e-01,
         -5.2337e-01, -1.5663e-01, -1.0482e+00,  6.1069e-01, -9.4205e-01,
          1.1882e+00,  6.0200e-01, -2.0642e+00,  2.8849e-01,  2.0760e+00,
          4.0039e-01,  1.1652e+00, -2.9463e-01, -1.5205e+00, -1.6449e+00],
        [ 1.2579e+00,  3.5462e-01, -1.1577e-01, -6.5914e-01, -1.5836e+00,
         -3.8455e-01, -1.5406e+00, -6.0496e-02,  6.9543e-02,  1.4911e+00,
          1.0519e+00,  6.9634e-01, -1.9538e-01, -3.0718e-01, -6.4901e-02,
         -1.2358e+00,  7.8366e-01, -1.4594e+00,  7.1021e-01,  8.2734e-01,
          2.2190e-02,  2.2691e+00,  1.4399e-01, -2.0849e+00, -3.7854e-01],
        [ 1.5853e+00,  3.2522e-01, -4.1777e-01, -1.4779e-03, -1.9379e+00,
          5.0598e-02, -1.0999e+00, -4.1108e-01,  4.2552e-01,  1.4998e+00,
          8.7926e-01,  8.1791e-01, -3.9518e-01, -1.7396e-01, -5.2887e-01,
         -6.8955e-01,  1.1123e+00, -2.3455e+00,  8.3882e-01,  1.9216e+00,
          4.3329e-01,  2.6732e+00, -2.9084e-01, -2.8213e+00, -7.8201e-01]],
       dtype=torch.float64, requires_grad=True)
Parameter containing:
tensor([3.8791, 3.0606, 4.1624, 2.6329, 3.2241], dtype=torch.float64,
       requires_grad=True)
Starting Training
layer weights:  Parameter containing:
tensor([[ 0.0707, -0.0865,  0.1688, -0.1848, -0.0049, -0.0391,  0.0832, -0.0457,
          0.1317,  0.1925,  0.1835, -0.0900,  0.1373,  0.1869,  0.1482, -0.1153,
         -0.0578,  0.0944, -0.0559,  0.0127, -0.1286, -0.1937,  0.1923, -0.1276,
          0.0302],
        [-0.1843, -0.1425, -0.0945,  0.0242, -0.0934,  0.1105, -0.1293, -0.0047,
          0.0205, -0.0187, -0.0515,  0.1693,  0.0874,  0.1954,  0.1322,  0.0441,
          0.1283,  0.1629, -0.1244,  0.0402,  0.1448, -0.1924, -0.0009,  0.0292,
          0.0364],
        [-0.1541, -0.0294,  0.1990,  0.0851, -0.1380, -0.0593, -0.0321,  0.1736,
         -0.1665, -0.0198,  0.1263,  0.0091,  0.1176, -0.1116, -0.1135, -0.0859,
         -0.0942, -0.0394, -0.1899,  0.1145,  0.0835, -0.0908, -0.1593, -0.0210,
         -0.0388],
        [ 0.1124, -0.0129,  0.0465,  0.0426, -0.0178,  0.0469,  0.1129, -0.0519,
         -0.0520, -0.1870,  0.1357,  0.0672,  0.0104,  0.1657,  0.0850, -0.0769,
          0.0569,  0.0623, -0.0409,  0.1882,  0.0180, -0.1784, -0.1459, -0.0795,
         -0.0823],
        [ 0.0698,  0.1317, -0.0327, -0.0884, -0.0692,  0.1838,  0.1350,  0.1589,
         -0.1921,  0.1501, -0.0268,  0.1264, -0.1859, -0.0915,  0.1397,  0.1517,
         -0.0675, -0.0712,  0.1527,  0.1945,  0.0755, -0.0075, -0.0774,  0.1566,
          0.1766]], dtype=torch.float64, requires_grad=True)
layer weights:  Parameter containing:
tensor([[ 0.1784, -0.0297, -0.1311, -0.1248, -0.0956, -0.1997, -0.1699, -0.1393,
         -0.1342,  0.1756,  0.1397,  0.1559,  0.1504,  0.0748, -0.0136,  0.1756,
         -0.1062, -0.0654, -0.0212,  0.0628, -0.1314, -0.0354,  0.0736,  0.1185,
         -0.0523],
        [-0.1765, -0.0251, -0.1022,  0.0634, -0.0727,  0.1285, -0.0954, -0.1477,
          0.1941, -0.0998, -0.0913, -0.1527,  0.1849, -0.0241,  0.1987, -0.0804,
         -0.0892, -0.0417,  0.1398,  0.0862, -0.0258, -0.0860, -0.0980, -0.0900,
         -0.1458],
        [-0.1962, -0.1804,  0.1572,  0.0169, -0.0904, -0.1787, -0.0042,  0.1883,
         -0.1609, -0.0493, -0.0724,  0.0227,  0.1123,  0.1080, -0.1755, -0.0562,
         -0.1985,  0.0070,  0.1688,  0.0119, -0.0220, -0.0805, -0.0386, -0.1679,
          0.0644],
        [-0.1703, -0.0314, -0.0322,  0.0964, -0.0381, -0.0004,  0.0427, -0.0737,
          0.0312,  0.1212, -0.0421, -0.1746, -0.1721,  0.1028, -0.1789, -0.1613,
          0.0756,  0.1857, -0.0719, -0.1468, -0.0976, -0.0217,  0.0923, -0.0673,
          0.1040],
        [-0.0836, -0.0552, -0.0146,  0.0253, -0.1303, -0.0199, -0.0314, -0.1475,
          0.1369,  0.0541,  0.0652, -0.0404,  0.1962,  0.0957, -0.0100,  0.1729,
          0.0302, -0.0651, -0.1867,  0.1339, -0.0770, -0.0307,  0.0475,  0.0482,
         -0.0903]], dtype=torch.float64, requires_grad=True)
Summary AFTER training

==============================================
Summary: 
State	Action	Next State	Reward
0 		 0 		  Q(s,a)=  tensor(4.1474, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 1 		  Q(s,a)=  tensor(3.1382, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 2 		  Q(s,a)=  tensor(4.3693, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 3 		  Q(s,a)=  tensor(3.2883, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 4 		  Q(s,a)=  tensor(4.1467, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 0 		  Q(s,a)=  tensor(3.8722, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 1 		  Q(s,a)=  tensor(2.3668, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 2 		  Q(s,a)=  tensor(2.7973, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 3 		  Q(s,a)=  tensor(2.6500, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 4 		  Q(s,a)=  tensor(2.3605, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 0 		  Q(s,a)=  tensor(2.6245, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 1 		  Q(s,a)=  tensor(4.4042, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 2 		  Q(s,a)=  tensor(3.2276, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 3 		  Q(s,a)=  tensor(3.5308, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 4 		  Q(s,a)=  tensor(3.5299, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 0 		  Q(s,a)=  tensor(3.5318, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 1 		  Q(s,a)=  tensor(1.6469, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 2 		  Q(s,a)=  tensor(2.8338, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 3 		  Q(s,a)=  tensor(2.2024, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 4 		  Q(s,a)=  tensor(2.3060, dtype=torch.float64, grad_fn=<SelectBackward0>)
==============================================

Best trajectory: 
Best trajectory from Test Environment
State:  0.07542857142857144  Action:  2  Reward Received:  0
State:  0.6363428571428571  Action:  1  Reward Received:  2.0
State:  0.35337142857142867  Action:  0  Reward Received:  0.1
State:  0.07542857142857144  Action:  2  Reward Received:  0
State:  0.6363428571428571  Action:  1  Reward Received:  2.0

Total Reward Received:  4.1
Taking a look at model parameters to see if weights are changing
Parameter containing:
tensor([[ 0.5839, -0.0240,  0.0581, -0.1648,  0.0074, -0.1961, -0.7291, -0.1866,
          0.1274,  0.3375,  1.4965,  2.0676,  0.5888, -1.3345, -1.1553, -0.7582,
         -1.4064,  0.7552, -0.5286,  1.1864, -0.4871, -0.7490,  0.3075,  1.0112,
         -2.0720],
        [-0.4088, -1.4979, -0.1797,  1.1982,  0.6918, -0.3717,  1.3288, -0.9094,
         -1.0650, -1.8973, -2.3189, -3.7876, -0.7787,  2.9147,  1.8418,  2.3932,
          3.8533, -2.0767,  0.7141, -1.7034,  1.4768,  0.5994, -1.6919, -1.7775,
          3.7282],
        [ 0.2642, -0.9912, -0.9832,  0.4899,  2.0253, -0.8346,  1.6739, -1.6529,
         -0.3828, -0.5110,  0.2123, -0.4529,  0.8153, -0.2712,  0.1027, -0.0554,
          0.9395, -0.6261, -1.0271,  0.3304,  1.0263, -0.8324, -1.0954,  0.4263,
          0.2016],
        [-0.1129, -0.9543, -0.1201,  0.7891,  0.6635, -0.3448,  0.8614, -0.7032,
         -0.6216, -0.9034, -0.8293, -1.6574, -0.5007,  1.2972,  0.4282,  0.9578,
          2.0356, -0.7647, -0.0237, -0.7575,  0.7641,  0.0674, -0.8462, -0.6716,
          1.6977],
        [ 0.1868, -1.2530, -1.2449,  0.7317,  2.0450, -0.8259,  2.0064, -2.1822,
         -0.4835, -0.9147, -0.5195, -1.8470,  0.5164,  0.7092,  0.8560,  0.9353,
          2.3230, -1.3994, -1.1508, -0.2620,  1.3407, -0.4857, -1.4711, -0.0053,
          1.3812]], dtype=torch.float64, requires_grad=True)
Parameter containing:
tensor([4.1141, 2.6480, 3.7828, 2.9338, 3.4484], dtype=torch.float64,
       requires_grad=True)
Starting Training
layer weights:  Parameter containing:
tensor([[ 0.1254,  0.0005,  0.0851, -0.1197, -0.0650,  0.0300, -0.0675, -0.0119,
         -0.1893, -0.1207,  0.0561, -0.0938,  0.0122, -0.1973,  0.0020, -0.1271,
         -0.1579, -0.0377, -0.1823, -0.0402, -0.0525, -0.0239, -0.1224,  0.0387,
          0.0072],
        [ 0.1424, -0.1652,  0.1011, -0.1514, -0.1166,  0.1880, -0.1674, -0.0651,
         -0.0525, -0.0513, -0.0016,  0.0786,  0.1642,  0.0559, -0.0607, -0.0790,
          0.0090,  0.1352,  0.0627, -0.1758, -0.0938, -0.1789, -0.1480, -0.1698,
         -0.0139],
        [-0.0675,  0.1637,  0.0163, -0.1243, -0.1878, -0.1443, -0.1521, -0.1314,
         -0.1938, -0.1317, -0.0571,  0.1508, -0.1116, -0.0165,  0.1118, -0.0729,
         -0.0061,  0.1057,  0.1437, -0.1274, -0.1620, -0.1349,  0.1941, -0.1752,
          0.1222],
        [ 0.0855, -0.0522,  0.0105,  0.1084,  0.0875, -0.1182,  0.1443, -0.1345,
         -0.0390, -0.1721, -0.0250, -0.0224, -0.1393,  0.1690,  0.1034, -0.0310,
          0.1407, -0.0376,  0.1774,  0.0853, -0.1695,  0.1738,  0.1946,  0.0255,
         -0.1969],
        [-0.1545,  0.1175,  0.0774,  0.1606,  0.0565,  0.1793, -0.1646, -0.0393,
          0.1236,  0.0871, -0.1456, -0.1622,  0.0317,  0.0869,  0.1294,  0.0751,
         -0.1911, -0.1334, -0.1832, -0.1767,  0.0643,  0.1633,  0.1718, -0.1466,
         -0.1999]], dtype=torch.float64, requires_grad=True)
layer weights:  Parameter containing:
tensor([[-0.1050, -0.0768, -0.1309,  0.0083,  0.1027, -0.0742,  0.1744, -0.1163,
         -0.1537, -0.1318,  0.0158,  0.0855,  0.1676, -0.1028,  0.1671,  0.1933,
          0.0410, -0.1596, -0.1572, -0.0011, -0.1074, -0.1207,  0.1155, -0.1800,
          0.1731],
        [ 0.1943,  0.1297,  0.0675, -0.1750,  0.0626, -0.0788,  0.0312, -0.1041,
          0.0268,  0.1985, -0.1462, -0.0841, -0.0278, -0.0057,  0.0987,  0.0332,
         -0.1577, -0.1500, -0.1096,  0.1207,  0.1790,  0.0075,  0.0864, -0.0911,
         -0.0777],
        [-0.1709,  0.1747, -0.0427,  0.1201,  0.1859, -0.0168, -0.1196, -0.1261,
         -0.1263,  0.1188, -0.1108, -0.1754,  0.0541, -0.0169,  0.0783,  0.1495,
          0.0018,  0.0352, -0.0208,  0.1216,  0.0534, -0.1085, -0.1674,  0.0953,
         -0.1751],
        [-0.0903,  0.0328, -0.0605,  0.0611,  0.1566,  0.1339, -0.1073,  0.0330,
          0.0552,  0.0402, -0.0189, -0.0692,  0.0058,  0.0824, -0.1810, -0.0006,
          0.0046, -0.0984,  0.0288, -0.1876,  0.1766, -0.0416,  0.1594, -0.0811,
         -0.0288],
        [ 0.1109, -0.1159,  0.1216,  0.1324,  0.1507, -0.1206,  0.1291, -0.0530,
         -0.1405,  0.0213, -0.1517,  0.1590,  0.0151, -0.1380,  0.1508,  0.0966,
         -0.0487, -0.1636, -0.1366, -0.0671,  0.0765, -0.0507,  0.1143, -0.0758,
          0.0183]], dtype=torch.float64, requires_grad=True)
Summary AFTER training

==============================================
Summary: 
State	Action	Next State	Reward
0 		 0 		  Q(s,a)=  tensor(3.7034, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 1 		  Q(s,a)=  tensor(2.9758, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 2 		  Q(s,a)=  tensor(4.4193, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 3 		  Q(s,a)=  tensor(3.3371, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 4 		  Q(s,a)=  tensor(3.7750, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 0 		  Q(s,a)=  tensor(3.9147, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 1 		  Q(s,a)=  tensor(2.2782, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 2 		  Q(s,a)=  tensor(2.9747, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 3 		  Q(s,a)=  tensor(2.8418, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 4 		  Q(s,a)=  tensor(2.6361, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 0 		  Q(s,a)=  tensor(2.6559, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 1 		  Q(s,a)=  tensor(4.1751, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 2 		  Q(s,a)=  tensor(3.1689, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 3 		  Q(s,a)=  tensor(3.8618, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 4 		  Q(s,a)=  tensor(3.9243, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 0 		  Q(s,a)=  tensor(4.0789, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 1 		  Q(s,a)=  tensor(1.9046, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 2 		  Q(s,a)=  tensor(2.5730, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 3 		  Q(s,a)=  tensor(2.7494, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 4 		  Q(s,a)=  tensor(2.8800, dtype=torch.float64, grad_fn=<SelectBackward0>)
==============================================

Best trajectory: 
Best trajectory from Test Environment
State:  0.05737142857142857  Action:  2  Reward Received:  0
State:  0.6467428571428572  Action:  1  Reward Received:  2.0
State:  0.34354285714285715  Action:  0  Reward Received:  0.1
State:  0.05737142857142857  Action:  2  Reward Received:  0
State:  0.6467428571428572  Action:  1  Reward Received:  2.0

Total Reward Received:  4.1
Taking a look at model parameters to see if weights are changing
Parameter containing:
tensor([[ 1.5326e+00,  2.4347e-01,  3.4094e-01, -6.7697e-01,  2.1785e-01,
          1.6600e-02,  2.3676e-01, -1.3337e+00,  1.6111e-01, -2.7681e-01,
         -2.1274e-01,  2.4131e+00,  1.8832e+00, -8.9285e-01, -1.9122e-01,
          6.8865e-01,  3.5691e-01, -1.7231e+00, -3.8894e-01, -7.7403e-01,
         -1.2702e+00, -1.0217e+00,  2.5866e+00, -1.1281e+00, -1.5072e-01],
        [-3.4760e+00, -9.7251e-01,  4.6219e-01,  1.8103e+00,  1.8161e-01,
         -1.6440e-01, -7.2315e-02,  2.7891e+00, -7.9919e-01,  8.3022e-01,
          5.5865e-02, -3.1924e+00, -2.2304e+00,  1.6930e+00,  4.5208e-02,
         -1.2806e+00, -4.2227e-01,  1.9981e+00,  1.2195e-01,  7.3303e-01,
          1.7836e+00,  1.5360e+00, -3.6278e+00,  9.4720e-01,  3.0671e-01],
        [-1.4977e+00, -1.2398e+00,  3.0156e-01,  1.9648e+00,  8.0336e-01,
          6.6140e-01, -8.3072e-01,  1.6127e+00, -5.0330e-01,  8.7566e-01,
          3.9072e-01,  7.3377e-02, -3.4947e-03, -5.8359e-01, -1.2005e+00,
          5.4469e-02, -4.5608e-01, -4.7392e-01,  6.7182e-01, -3.0855e-01,
         -1.2118e-01, -5.9071e-01, -5.3959e-01, -7.0824e-01, -3.0934e-02],
        [-2.0818e+00, -6.5379e-01,  3.3715e-01,  1.2510e+00,  2.8266e-01,
          1.2092e-01, -1.8670e-01,  1.6873e+00, -4.1792e-01,  4.3860e-01,
          6.4035e-02, -1.4744e+00, -9.8123e-01,  9.7576e-01, -3.6152e-01,
         -7.3196e-01, -1.0334e-01,  8.7851e-01,  1.3687e-01, -1.5688e-02,
          9.0996e-01,  7.0624e-01, -1.6211e+00,  3.1332e-01,  1.3595e-01],
        [-2.3572e+00, -1.6578e+00,  3.8802e-01,  2.4319e+00,  7.2565e-01,
          4.7232e-01, -4.9055e-01,  2.5341e+00, -7.0057e-01,  9.1590e-01,
          4.6091e-01, -1.0595e+00, -1.0647e+00,  5.4314e-02, -8.0049e-01,
         -3.7969e-01, -5.7147e-01,  4.6171e-01,  6.4758e-01,  1.9751e-02,
          7.3145e-01,  2.2387e-01, -1.8397e+00, -1.6443e-01,  3.9372e-01]],
       dtype=torch.float64, requires_grad=True)
Parameter containing:
tensor([3.1854, 3.2825, 3.9974, 3.3260, 3.5088], dtype=torch.float64,
       requires_grad=True)
