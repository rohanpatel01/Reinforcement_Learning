Starting Training
layer weights:  Parameter containing:
tensor([[-0.0122, -0.1646,  0.0070, -0.0344, -0.1068, -0.0241, -0.1616, -0.1675,
         -0.1032,  0.0402, -0.1989,  0.1326, -0.1308,  0.0738,  0.0394,  0.0951,
          0.1954, -0.0305,  0.0156,  0.0136, -0.1332,  0.1900, -0.0389, -0.0514,
         -0.1441],
        [ 0.0177, -0.0242,  0.0165,  0.0530, -0.1450, -0.0680, -0.1623, -0.1914,
         -0.0363, -0.1038,  0.1955,  0.0542, -0.0534,  0.1437, -0.0528, -0.0510,
          0.0907,  0.0430,  0.0709,  0.1121, -0.0935, -0.1074,  0.1001, -0.1418,
         -0.1370],
        [-0.1080,  0.0392,  0.1780, -0.0724, -0.0343, -0.1183, -0.1748,  0.0583,
          0.0325,  0.1434, -0.0723, -0.0152,  0.1098, -0.1941,  0.0561, -0.0658,
         -0.0246, -0.1638,  0.0939, -0.0683,  0.0135, -0.0688, -0.1482,  0.1689,
          0.0678],
        [-0.1109, -0.0447, -0.1232, -0.1396,  0.1048, -0.0570,  0.1803, -0.0821,
         -0.0566, -0.0046, -0.1383, -0.0521, -0.0481, -0.1462, -0.1770,  0.1246,
         -0.0094, -0.0360, -0.0728, -0.1301, -0.1233,  0.1737,  0.1144,  0.0228,
         -0.1013],
        [ 0.1083,  0.0221, -0.1625,  0.1688,  0.0046, -0.1695, -0.0150,  0.0894,
          0.0805, -0.0729,  0.0282,  0.0224,  0.0762, -0.1697, -0.1314, -0.1490,
          0.0719, -0.1531,  0.1453,  0.0876, -0.0246,  0.0323,  0.0472, -0.1056,
          0.1690]], dtype=torch.float64, requires_grad=True)
layer weights:  Parameter containing:
tensor([[-0.0182,  0.0104,  0.0961,  0.0534,  0.1302,  0.0853,  0.1310,  0.1684,
         -0.0647,  0.0695, -0.1038, -0.1765,  0.0758,  0.1127,  0.0417,  0.1043,
          0.1409, -0.0149, -0.0020,  0.1204, -0.0924,  0.0444,  0.0851, -0.0247,
         -0.1054],
        [-0.0645,  0.1601,  0.0652,  0.1829, -0.0519, -0.0481,  0.1338,  0.1490,
          0.1818, -0.0932, -0.1113,  0.0956,  0.0016, -0.1920, -0.1988, -0.0423,
         -0.0752, -0.0377,  0.0947,  0.0119, -0.1603,  0.0639, -0.0499, -0.1693,
         -0.0458],
        [-0.1393, -0.0396, -0.0847, -0.0290,  0.1276, -0.1573, -0.1624,  0.1636,
          0.0123, -0.1612, -0.0679, -0.0771, -0.1710, -0.0106, -0.0687,  0.0788,
          0.1045, -0.0509,  0.1479, -0.1860, -0.0848, -0.1406, -0.1400, -0.1554,
          0.0829],
        [-0.1088,  0.1323, -0.0909, -0.0544,  0.1572, -0.1567, -0.1059, -0.1206,
          0.0535, -0.0253, -0.0089,  0.1310, -0.0450,  0.0517,  0.0989,  0.0631,
         -0.0135, -0.0812, -0.1392, -0.0826,  0.0728, -0.0295, -0.0813,  0.0399,
         -0.0084],
        [-0.1854,  0.0833, -0.0159,  0.0157,  0.0419,  0.1356,  0.1560, -0.0598,
          0.1673,  0.0761, -0.0683,  0.0804,  0.1434, -0.0106,  0.1594,  0.0847,
         -0.1849,  0.1808,  0.1699,  0.1657, -0.1455, -0.0246,  0.0765,  0.0730,
          0.0839]], dtype=torch.float64, requires_grad=True)
Summary AFTER training

==============================================
Summary: 
State	Action	Next State	Reward
0 		 0 		  Q(s,a)=  tensor(3.9942, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 1 		  Q(s,a)=  tensor(3.4745, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 2 		  Q(s,a)=  tensor(5.3334, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 3 		  Q(s,a)=  tensor(3.7552, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 4 		  Q(s,a)=  tensor(3.8128, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 0 		  Q(s,a)=  tensor(3.9759, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 1 		  Q(s,a)=  tensor(2.5236, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 2 		  Q(s,a)=  tensor(3.7144, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 3 		  Q(s,a)=  tensor(3.3316, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 4 		  Q(s,a)=  tensor(2.9065, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 0 		  Q(s,a)=  tensor(2.6205, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 1 		  Q(s,a)=  tensor(4.8134, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 2 		  Q(s,a)=  tensor(3.9254, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 3 		  Q(s,a)=  tensor(4.5996, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 4 		  Q(s,a)=  tensor(3.8604, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 0 		  Q(s,a)=  tensor(3.7330, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 1 		  Q(s,a)=  tensor(2.6822, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 2 		  Q(s,a)=  tensor(3.5188, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 3 		  Q(s,a)=  tensor(3.3471, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 4 		  Q(s,a)=  tensor(3.1565, dtype=torch.float64, grad_fn=<SelectBackward0>)
==============================================

Best trajectory: 
Best trajectory from Test Environment
State:  0.0752  Action:  2  Reward Received:  0
State:  0.6531428571428571  Action:  1  Reward Received:  2.0
State:  0.35200000000000004  Action:  0  Reward Received:  0.1
State:  0.0752  Action:  2  Reward Received:  0
State:  0.6531428571428571  Action:  1  Reward Received:  2.0

Total Reward Received:  4.1
Taking a look at model parameters to see if weights are changing
Parameter containing:
tensor([[-0.4429,  3.4839,  0.8346, -1.4592,  0.3612, -0.6426,  0.5266,  2.2502,
          0.9316, -1.8169,  0.3530, -0.5724, -1.0206,  0.3197, -1.1039,  0.8483,
         -2.0084, -1.6384,  0.2541, -0.7090, -0.9290, -0.7579, -0.7548,  0.8800,
          1.8775],
        [-0.3534, -4.7803, -2.5874,  2.9779, -0.7327, -0.0856, -0.6160, -4.3212,
         -0.9246,  3.4574,  0.1570,  0.5740,  0.3619,  0.0533,  1.7870, -2.3588,
          2.9607,  1.1139,  0.3497,  1.8065,  2.4060,  2.4803,  1.1887, -1.6288,
         -2.4864],
        [-1.6339,  0.5028, -1.4530,  0.8302,  0.9770, -1.9858, -0.2837, -0.3966,
         -0.0140,  0.4916,  0.5486, -0.7544, -1.6445,  1.3413, -0.0096, -0.4204,
         -0.0450, -1.7452,  0.7619, -0.5771,  1.6742,  1.4980,  0.0260, -0.3439,
          0.9296],
        [-0.0247, -2.6027, -1.6077,  1.4066, -0.6518,  0.1139, -0.5015, -2.8677,
         -0.3408,  2.0161,  0.3184,  0.6453,  0.2330, -0.0818,  1.3098, -1.4742,
          1.6859,  0.7212,  0.0520,  1.3147,  1.3700,  1.1910,  0.5573, -0.6903,
         -1.4136],
        [-1.1017, -1.1465, -1.5512,  1.2375,  0.2405, -0.8809, -0.1770, -1.7111,
         -0.2320,  1.4135,  0.2738, -0.1876, -0.5548,  0.7143,  0.7259, -0.8936,
          0.5941, -0.3990,  0.5113,  0.4267,  1.4679,  1.4830,  0.4825, -0.5077,
         -0.2442]], dtype=torch.float64, requires_grad=True)
Parameter containing:
tensor([3.9184, 2.8674, 4.6907, 3.3390, 3.2499], dtype=torch.float64,
       requires_grad=True)
Starting Training
layer weights:  Parameter containing:
tensor([[-3.3641e-02,  1.0978e-01, -3.1487e-02,  9.3150e-02, -2.7422e-02,
          3.8942e-02,  1.5582e-01, -1.8260e-01,  2.2059e-02, -1.4689e-01,
         -5.8979e-02, -1.4812e-02, -1.3051e-02, -2.5885e-02, -3.2888e-02,
          3.9786e-02, -8.7099e-02, -1.3576e-01, -2.4375e-02,  1.0910e-04,
         -5.6863e-02,  6.5020e-03, -2.2407e-02, -2.5382e-02, -1.2401e-01],
        [ 8.5042e-02, -6.6711e-02, -1.4932e-01, -2.4791e-03, -3.6333e-02,
         -1.1940e-01,  3.2675e-02, -1.0506e-01,  4.1077e-02,  1.0507e-01,
          8.9982e-02,  1.1951e-01,  1.0871e-01, -4.8847e-02, -4.8493e-02,
         -5.7573e-02, -3.9282e-02, -1.0465e-01,  7.8043e-02,  7.9328e-02,
         -1.0695e-01, -1.8619e-01, -9.5952e-02, -3.7710e-02, -5.7136e-02],
        [-4.3471e-02,  1.4762e-01,  1.7742e-01, -6.0372e-02,  1.6434e-01,
         -5.8612e-02,  1.8792e-01,  3.1035e-02, -1.8567e-01,  6.4072e-02,
          1.9924e-01, -3.8001e-02, -1.3713e-02,  1.0320e-01, -7.3474e-02,
          1.0375e-01,  1.7861e-01, -1.8966e-01, -1.6216e-01, -1.4067e-01,
          1.9574e-01,  8.4125e-02, -1.5700e-01,  9.8385e-02,  1.0459e-02],
        [-1.8628e-01, -4.9040e-03,  2.1106e-02, -4.3824e-02,  2.0664e-02,
          1.7895e-01, -1.8976e-01,  2.9927e-02, -1.4686e-01, -9.8842e-02,
          5.2219e-02, -1.9906e-01,  1.4547e-01, -8.0944e-02, -1.5515e-01,
         -1.7783e-02,  1.5103e-01, -1.5155e-01,  1.1994e-01,  8.0112e-02,
          1.3089e-01, -1.9387e-01, -1.4839e-01, -5.2929e-06,  1.3791e-01],
        [ 1.2459e-01,  1.6051e-01, -1.9238e-03,  1.2506e-01,  1.2824e-02,
         -1.0439e-01,  9.4690e-02, -1.4181e-01,  1.8280e-01,  2.3098e-03,
          7.3851e-02,  1.8221e-01, -1.6784e-01,  1.7029e-01,  4.9506e-02,
          6.0414e-02, -6.3080e-02,  1.2459e-02, -1.8417e-02,  1.2060e-01,
         -1.9386e-01, -1.3377e-01, -3.9871e-02, -1.9456e-01,  5.8001e-02]],
       dtype=torch.float64, requires_grad=True)
layer weights:  Parameter containing:
tensor([[ 0.1232, -0.0875,  0.0661,  0.0226,  0.1338,  0.0866, -0.0635, -0.1547,
          0.0227, -0.1485,  0.0893,  0.0521, -0.1571, -0.0972,  0.1761, -0.0321,
         -0.0790, -0.1538, -0.1492,  0.0772,  0.0141, -0.1654,  0.0249, -0.0360,
          0.0916],
        [-0.1239, -0.0436, -0.0551,  0.1261,  0.1232, -0.1768, -0.0253, -0.1850,
          0.0986,  0.1167, -0.1056, -0.0523,  0.0989, -0.1548, -0.1062,  0.0591,
          0.1300,  0.1580,  0.0873,  0.1870, -0.0733, -0.1500, -0.1606,  0.0010,
         -0.0036],
        [ 0.1506, -0.1491,  0.1012, -0.1251,  0.1831,  0.0349,  0.1655,  0.0428,
          0.1503, -0.1023,  0.0237,  0.1927,  0.1681,  0.0404, -0.1182, -0.0266,
          0.1415,  0.0734, -0.1129, -0.0742, -0.0520, -0.1291,  0.0484, -0.0398,
          0.1263],
        [ 0.0813,  0.0402, -0.1130,  0.1239,  0.1136,  0.0676,  0.1834,  0.0638,
         -0.1209,  0.0972, -0.0804,  0.0311,  0.1158, -0.1998, -0.0247,  0.0314,
          0.0626, -0.0869, -0.0921,  0.1601, -0.1264, -0.1247, -0.0954,  0.0936,
          0.0270],
        [ 0.0847,  0.1042,  0.0101,  0.0978,  0.1460, -0.0700,  0.0518,  0.1169,
         -0.1611,  0.1023, -0.1389, -0.1604,  0.0105,  0.1367,  0.1096,  0.0429,
          0.1444, -0.1726, -0.1463,  0.1818, -0.0932, -0.1167,  0.0660,  0.0769,
         -0.1067]], dtype=torch.float64, requires_grad=True)
Summary AFTER training

==============================================
Summary: 
State	Action	Next State	Reward
0 		 0 		  Q(s,a)=  tensor(3.9571, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 1 		  Q(s,a)=  tensor(3.1127, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 2 		  Q(s,a)=  tensor(4.3486, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 3 		  Q(s,a)=  tensor(3.4168, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 4 		  Q(s,a)=  tensor(3.9510, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 0 		  Q(s,a)=  tensor(3.5677, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 1 		  Q(s,a)=  tensor(2.3954, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 2 		  Q(s,a)=  tensor(2.8857, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 3 		  Q(s,a)=  tensor(3.2055, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 4 		  Q(s,a)=  tensor(2.7473, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 0 		  Q(s,a)=  tensor(2.0427, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 1 		  Q(s,a)=  tensor(4.6390, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 2 		  Q(s,a)=  tensor(3.1123, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 3 		  Q(s,a)=  tensor(4.4968, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 4 		  Q(s,a)=  tensor(3.5284, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 0 		  Q(s,a)=  tensor(2.9632, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 1 		  Q(s,a)=  tensor(2.1555, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 2 		  Q(s,a)=  tensor(2.7589, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 3 		  Q(s,a)=  tensor(3.3487, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 4 		  Q(s,a)=  tensor(2.9491, dtype=torch.float64, grad_fn=<SelectBackward0>)
==============================================

Best trajectory: 
Best trajectory from Test Environment
State:  0.06468571428571429  Action:  2  Reward Received:  0
State:  0.6448  Action:  1  Reward Received:  2.0
State:  0.36160000000000003  Action:  0  Reward Received:  0.1
State:  0.06468571428571429  Action:  2  Reward Received:  0
State:  0.6448  Action:  1  Reward Received:  2.0

Total Reward Received:  4.1
Taking a look at model parameters to see if weights are changing
Parameter containing:
tensor([[-1.8411, -0.1952,  0.4521, -1.3516,  1.3268,  0.7096,  0.3820,  0.6269,
         -0.5947, -2.2478,  1.6679,  0.5094,  0.8461,  0.4676,  0.6116, -0.5827,
          0.4451, -0.7734, -0.5342,  0.5339, -0.6203, -0.1706, -0.2588, -0.3646,
         -0.7411],
        [ 2.8753,  1.6442,  0.9970,  3.4468, -1.4864, -1.9325, -0.8158, -1.7444,
          1.1377,  3.0576, -2.8904, -2.0550, -1.9352, -1.6141, -0.4706,  0.7270,
         -0.9184,  0.5046,  0.9438, -0.2269,  0.2232, -0.3029,  0.9341,  0.0968,
          0.5114],
        [ 0.3200,  1.1072,  2.3046,  1.0103,  0.4615, -1.0193, -0.0503, -0.1792,
          0.2444, -0.2777, -0.2429, -0.6659,  0.1070,  0.1272, -0.2302,  0.4150,
          0.6240, -1.0193, -0.5514, -0.6434, -0.8642, -0.1638, -0.0689, -1.2026,
         -1.1887],
        [ 1.5536,  1.0927,  0.5353,  1.9399, -0.6553, -0.8613, -0.1988, -0.7549,
          0.4103,  1.5202, -1.5122, -1.1442, -0.9825, -1.0475, -0.1132,  0.2745,
         -0.5483,  0.0819,  0.4600,  0.0970, -0.0345, -0.2244,  0.6310,  0.1934,
          0.2691],
        [ 0.7977,  1.3648,  1.9701,  1.5592,  0.1164, -1.1963, -0.2290, -0.2765,
          0.1358,  0.5392, -0.8033, -1.0805, -0.3076,  0.0684, -0.0559,  0.6108,
          0.4563, -0.9678, -0.3804, -0.4094, -0.6335, -0.1128,  0.1104, -0.8593,
         -1.0494]], dtype=torch.float64, requires_grad=True)
Parameter containing:
tensor([3.9131, 2.7270, 4.1021, 3.1052, 3.6298], dtype=torch.float64,
       requires_grad=True)
Starting Training
layer weights:  Parameter containing:
tensor([[ 0.0749, -0.1297, -0.0265, -0.1428,  0.0096, -0.1268,  0.1577,  0.0453,
          0.1035,  0.1828,  0.1045, -0.1489, -0.1742,  0.1013,  0.1370, -0.0815,
          0.1448,  0.0992,  0.0081, -0.1585,  0.0235, -0.1774,  0.0261, -0.1293,
         -0.0209],
        [ 0.0861, -0.1243,  0.1711, -0.1200,  0.0273,  0.0675, -0.0450, -0.0901,
          0.1163, -0.0337, -0.0812, -0.1421,  0.1965, -0.0545,  0.1257, -0.0756,
          0.0244, -0.1144, -0.0758, -0.1123,  0.1627, -0.1100, -0.0433, -0.1056,
         -0.1844],
        [-0.1617, -0.1827,  0.0679, -0.0554, -0.0731, -0.0099, -0.1690,  0.0536,
          0.1899, -0.0972, -0.0152, -0.1464, -0.1427,  0.0788, -0.0998,  0.1815,
         -0.1450, -0.0785,  0.0387, -0.1516, -0.1565, -0.0160, -0.0061,  0.1620,
         -0.0430],
        [ 0.0265, -0.0136,  0.0527, -0.1656, -0.1215, -0.0487, -0.0064,  0.0285,
         -0.1352, -0.0805, -0.1519, -0.0451,  0.1221,  0.1790,  0.1286, -0.0137,
          0.0859,  0.1649, -0.0711, -0.0616,  0.0031,  0.1735,  0.0364,  0.0256,
          0.1744],
        [ 0.0926,  0.0995,  0.1316,  0.1233, -0.1259, -0.1677, -0.1686,  0.1920,
         -0.0334, -0.1477,  0.1656,  0.0903, -0.1766,  0.1684,  0.0454,  0.0711,
         -0.1222,  0.0937,  0.1577,  0.0929,  0.1332,  0.0530,  0.0911, -0.0168,
          0.1655]], dtype=torch.float64, requires_grad=True)
layer weights:  Parameter containing:
tensor([[ 0.1128,  0.1356,  0.1511, -0.0043,  0.1801,  0.1770,  0.0023,  0.1607,
          0.0450,  0.0857,  0.0793, -0.1482, -0.0887, -0.0046, -0.0997,  0.0070,
          0.1561,  0.1914,  0.0980, -0.0090, -0.0929, -0.1408,  0.0061,  0.1112,
          0.1869],
        [ 0.0385, -0.0666, -0.0685,  0.0753,  0.1914, -0.0444,  0.0174, -0.1343,
          0.1440, -0.0781, -0.1044,  0.1676,  0.0248,  0.0504,  0.0631, -0.0579,
         -0.1336,  0.0687,  0.1641,  0.0168, -0.1681, -0.1381, -0.0311,  0.1533,
         -0.1280],
        [-0.0286,  0.1901,  0.1858,  0.0941, -0.1246,  0.1334, -0.1695,  0.0176,
          0.0525,  0.1082, -0.1185,  0.1869,  0.0867, -0.0169, -0.1509,  0.0204,
         -0.1655, -0.1378,  0.1470, -0.1912,  0.0661, -0.1892,  0.0769,  0.0282,
          0.0984],
        [ 0.0714,  0.1196,  0.1274,  0.0338, -0.0039,  0.1169, -0.1495, -0.0413,
         -0.1341, -0.0097, -0.1762, -0.0301,  0.0251, -0.1699, -0.0692,  0.1705,
         -0.1052, -0.1485,  0.1141,  0.1909,  0.0174, -0.0874, -0.1887,  0.0526,
          0.1160],
        [-0.0232, -0.1247,  0.1426,  0.1075,  0.0316,  0.0124,  0.0539,  0.0725,
         -0.1842, -0.1277,  0.0117,  0.1201,  0.1697, -0.1341,  0.1365, -0.1387,
          0.1277, -0.1707,  0.1854, -0.0799, -0.0163,  0.0687,  0.1576,  0.0190,
          0.0226]], dtype=torch.float64, requires_grad=True)
Summary AFTER training

==============================================
Summary: 
State	Action	Next State	Reward
0 		 0 		  Q(s,a)=  tensor(3.9248, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 1 		  Q(s,a)=  tensor(3.2346, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 2 		  Q(s,a)=  tensor(3.8810, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 3 		  Q(s,a)=  tensor(3.1833, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 4 		  Q(s,a)=  tensor(3.9708, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 0 		  Q(s,a)=  tensor(3.8347, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 1 		  Q(s,a)=  tensor(2.3688, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 2 		  Q(s,a)=  tensor(2.5255, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 3 		  Q(s,a)=  tensor(2.7076, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 4 		  Q(s,a)=  tensor(2.2418, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 0 		  Q(s,a)=  tensor(2.2183, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 1 		  Q(s,a)=  tensor(4.4726, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 2 		  Q(s,a)=  tensor(2.9338, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 3 		  Q(s,a)=  tensor(3.7783, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 4 		  Q(s,a)=  tensor(3.3866, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 0 		  Q(s,a)=  tensor(3.0965, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 1 		  Q(s,a)=  tensor(2.1602, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 2 		  Q(s,a)=  tensor(2.7411, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 3 		  Q(s,a)=  tensor(2.4339, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 4 		  Q(s,a)=  tensor(1.7963, dtype=torch.float64, grad_fn=<SelectBackward0>)
==============================================

Best trajectory: 
Best trajectory from Test Environment
State:  0.07428571428571429  Action:  4  Reward Received:  0.1
State:  0.07428571428571429  Action:  4  Reward Received:  0.1
State:  0.07428571428571429  Action:  4  Reward Received:  0.1
State:  0.07428571428571429  Action:  4  Reward Received:  0.1
State:  0.07428571428571429  Action:  4  Reward Received:  0.1

Total Reward Received:  0.5
Taking a look at model parameters to see if weights are changing
Parameter containing:
tensor([[ 4.4935e-01, -5.0154e-01,  8.3382e-01,  2.4993e-02,  7.3435e-01,
         -1.6281e+00,  3.8483e-01,  9.1545e-01, -4.3165e-01,  2.1571e-01,
         -1.4785e+00,  1.0159e+00, -1.2566e+00, -6.5378e-01, -2.5287e-01,
          1.3301e-01,  1.3651e+00,  4.4080e-01,  1.4058e+00,  8.1188e-01,
         -1.7216e+00, -3.7591e-01,  1.3820e+00, -2.3453e+00, -1.0503e+00],
        [-1.1202e+00,  1.8008e+00, -8.1622e-01, -4.8471e-01, -1.3010e+00,
          2.1343e+00, -9.0010e-01, -1.4714e+00,  1.1778e+00, -1.2512e+00,
          2.6271e+00, -2.3752e+00,  1.4619e+00,  3.2630e-01,  1.0703e+00,
         -1.5013e-01, -2.5240e+00, -7.6424e-01, -2.2957e+00, -7.3382e-01,
          2.7646e+00,  5.3387e-01, -2.8285e+00,  4.4414e+00,  9.9212e-01],
        [-1.0239e+00,  9.0031e-01,  2.3013e-01, -9.4300e-01,  4.8669e-01,
          4.1432e-04, -7.2850e-01,  3.3637e-01,  1.0712e+00,  1.6292e-01,
          5.5360e-01, -1.4853e+00,  1.8126e-01, -7.5197e-02, -5.3513e-01,
          9.9590e-01, -1.6804e-01, -6.1584e-01,  9.8899e-01,  2.8475e-01,
          5.4440e-01, -1.2497e+00, -7.2728e-01,  7.7244e-01, -8.0666e-01],
        [-5.3691e-01,  1.2411e+00, -1.6186e-01, -2.4430e-01, -9.3677e-01,
          1.1380e+00, -6.0967e-01, -7.6275e-01,  3.8672e-01, -8.0151e-01,
          1.2796e+00, -1.2744e+00,  6.9215e-01, -1.6677e-01,  6.8476e-01,
          7.3664e-02, -1.3978e+00, -6.0169e-01, -1.2832e+00, -9.4132e-02,
          1.6224e+00,  4.5023e-01, -1.6319e+00,  2.3976e+00,  6.1437e-01],
        [-1.4766e+00,  1.3161e+00, -3.2088e-01, -1.0747e+00, -2.4781e-01,
          1.0811e+00, -9.3733e-01, -4.1897e-01,  1.1273e+00, -6.6690e-01,
          1.9507e+00, -2.6429e+00,  9.9889e-01, -1.9384e-02,  1.9821e-01,
          5.5561e-01, -1.1582e+00, -1.0337e+00, -4.3627e-01, -2.0266e-01,
          1.8637e+00, -5.7057e-01, -2.0083e+00,  2.8609e+00, -1.0709e-01]],
       dtype=torch.float64, requires_grad=True)
Parameter containing:
tensor([3.9806, 2.9271, 3.3976, 2.9782, 3.5090], dtype=torch.float64,
       requires_grad=True)
Starting Training
layer weights:  Parameter containing:
tensor([[-1.6896e-01,  1.7192e-01, -7.4771e-02,  1.1522e-01,  1.5510e-01,
          1.3285e-01,  9.8002e-02,  3.9429e-02, -5.5384e-02, -1.2259e-01,
          1.1184e-01, -1.3264e-01, -1.5459e-01,  1.4982e-04,  8.4874e-03,
          4.7584e-02, -2.8807e-02, -3.1840e-02, -1.2491e-01,  1.4964e-01,
          7.3206e-02, -8.5353e-02, -1.5132e-01,  3.9673e-03, -8.0841e-02],
        [ 3.7628e-02, -3.4780e-03,  7.4612e-02,  1.5980e-01, -1.4048e-01,
         -1.8298e-01, -1.9113e-02,  2.7601e-02,  9.9663e-02,  1.3548e-01,
         -5.9294e-02,  1.0196e-01, -1.9460e-01, -1.0136e-01,  1.8741e-01,
         -1.5735e-01,  3.4126e-02,  1.4356e-01, -1.7231e-01,  1.0261e-01,
         -5.6675e-02,  1.0313e-01,  7.4927e-02, -6.0574e-02,  1.8496e-02],
        [-1.1103e-01, -1.5800e-01, -1.1564e-01,  1.4247e-01,  5.3102e-02,
         -1.8626e-01, -5.3023e-02,  1.5933e-01,  3.2386e-02, -1.2657e-01,
          1.8981e-01, -4.7676e-02,  2.1538e-02, -1.1288e-01, -1.2879e-01,
         -1.0402e-01, -1.5214e-01,  6.9609e-03, -7.9750e-02,  1.0315e-01,
          3.3093e-02, -8.7230e-02, -7.9476e-02,  9.4473e-02, -1.8606e-01],
        [ 8.7695e-02, -7.2224e-02,  4.7068e-02,  6.1391e-02, -3.9575e-02,
          4.6414e-02, -8.5295e-02, -1.0859e-01, -1.7741e-01, -1.3932e-01,
         -1.5652e-01,  9.3484e-02,  1.7277e-01,  1.1731e-01,  4.3665e-02,
          1.2642e-01,  1.2342e-01,  1.1173e-01, -1.0570e-01, -1.5568e-01,
         -1.2180e-01,  1.1187e-01,  9.3504e-02, -1.5901e-01,  2.1568e-02],
        [ 1.8215e-01, -1.3113e-01, -1.6850e-01,  1.6990e-01,  1.9428e-01,
          1.3258e-01, -1.7102e-01, -8.2337e-02, -1.0196e-01, -1.7148e-01,
          6.4375e-03, -1.0166e-01, -4.5187e-02, -1.5506e-02, -3.0462e-02,
         -2.5935e-02,  4.1555e-02, -1.5179e-02,  1.8183e-01,  5.0097e-02,
          6.9585e-02,  6.9313e-02,  1.0807e-01, -1.5575e-01,  6.5463e-03]],
       dtype=torch.float64, requires_grad=True)
layer weights:  Parameter containing:
tensor([[-0.0861, -0.1703, -0.1605, -0.0901, -0.1998,  0.1498, -0.1747, -0.1246,
         -0.0754,  0.1379, -0.0249, -0.1539,  0.0128,  0.1249, -0.1139, -0.0395,
          0.0839,  0.0114, -0.0110,  0.0165,  0.0643,  0.0343,  0.0043, -0.1145,
         -0.1317],
        [ 0.1779,  0.0358, -0.0960, -0.1889,  0.1072, -0.0264,  0.1117,  0.1727,
          0.1447,  0.0929,  0.1328, -0.1376,  0.0997,  0.1503, -0.0333, -0.0622,
          0.0535, -0.1559,  0.0170, -0.1096, -0.0400,  0.0498, -0.0126, -0.0169,
          0.1216],
        [-0.0343, -0.0335, -0.0327, -0.1644,  0.1743, -0.0468, -0.1437, -0.1844,
          0.0933, -0.0383, -0.1567,  0.1041, -0.0893, -0.1824, -0.1624, -0.1362,
         -0.0753, -0.0435, -0.0756, -0.1458,  0.1293,  0.0517,  0.1453,  0.0007,
         -0.1534],
        [-0.1821, -0.1258, -0.0339,  0.1775,  0.0369, -0.1035,  0.1184, -0.0349,
         -0.1510, -0.0116,  0.1187,  0.0238,  0.1301, -0.1993, -0.1354, -0.0518,
          0.1106, -0.0477,  0.0616, -0.0520,  0.0163, -0.0625, -0.1611, -0.0488,
          0.0165],
        [-0.1753,  0.0781, -0.1934,  0.1686, -0.0829, -0.1611,  0.1233, -0.1708,
          0.1076, -0.1364,  0.1261, -0.0191,  0.0693, -0.1566,  0.1014,  0.1577,
          0.0569,  0.1130,  0.1045, -0.0336, -0.1530,  0.0314, -0.1175, -0.1061,
          0.0959]], dtype=torch.float64, requires_grad=True)
Summary AFTER training

==============================================
Summary: 
State	Action	Next State	Reward
0 		 0 		  Q(s,a)=  tensor(4.3193, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 1 		  Q(s,a)=  tensor(3.2749, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 2 		  Q(s,a)=  tensor(4.8331, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 3 		  Q(s,a)=  tensor(3.6366, dtype=torch.float64, grad_fn=<SelectBackward0>)
0 		 4 		  Q(s,a)=  tensor(4.2426, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 0 		  Q(s,a)=  tensor(4.3701, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 1 		  Q(s,a)=  tensor(2.6825, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 2 		  Q(s,a)=  tensor(3.3006, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 3 		  Q(s,a)=  tensor(3.0196, dtype=torch.float64, grad_fn=<SelectBackward0>)
1 		 4 		  Q(s,a)=  tensor(2.4148, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 0 		  Q(s,a)=  tensor(3.1570, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 1 		  Q(s,a)=  tensor(4.9922, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 2 		  Q(s,a)=  tensor(3.6797, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 3 		  Q(s,a)=  tensor(4.4786, dtype=torch.float64, grad_fn=<SelectBackward0>)
2 		 4 		  Q(s,a)=  tensor(3.2081, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 0 		  Q(s,a)=  tensor(4.1918, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 1 		  Q(s,a)=  tensor(2.5941, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 2 		  Q(s,a)=  tensor(3.6744, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 3 		  Q(s,a)=  tensor(3.0889, dtype=torch.float64, grad_fn=<SelectBackward0>)
3 		 4 		  Q(s,a)=  tensor(2.1172, dtype=torch.float64, grad_fn=<SelectBackward0>)
==============================================

Best trajectory: 
Best trajectory from Test Environment
State:  0.06845714285714286  Action:  2  Reward Received:  0
State:  0.6265142857142858  Action:  1  Reward Received:  2.0
State:  0.3485714285714286  Action:  0  Reward Received:  0.1
State:  0.06845714285714286  Action:  2  Reward Received:  0
State:  0.6265142857142858  Action:  1  Reward Received:  2.0

Total Reward Received:  4.1
Taking a look at model parameters to see if weights are changing
Parameter containing:
tensor([[-0.2749, -0.7428,  0.3469,  0.3093,  1.1003,  0.6023,  1.3790, -1.9521,
          0.7212, -0.1039, -1.9782,  0.1450, -1.3871, -0.4785,  0.0343,  0.0447,
         -1.6470,  1.0744, -0.0636, -0.0362,  0.0227, -0.0132,  0.5407,  1.3173,
          0.6055],
        [ 0.1463,  1.0474, -0.6046, -0.6062, -1.9697, -0.5280, -2.5772,  3.4503,
         -0.7466, -0.6344,  3.5579, -0.0900,  4.1090,  2.5216, -0.1700, -0.3921,
          2.7137, -2.4760, -0.3476,  0.4616, -1.2852, -0.4526,  0.0284, -2.8579,
         -1.6852],
        [ 1.2110, -1.4895,  1.2441,  0.3608, -0.4395, -0.6464, -0.4767, -0.4923,
         -0.1519, -0.4569,  0.0098, -0.3989,  2.2079,  0.7938,  1.0483, -1.6357,
          0.4067,  0.4811, -1.2054,  0.9816, -0.2335, -0.9686,  0.6808, -0.7429,
         -0.7611],
        [-0.0150,  0.2447, -0.0527,  0.0820, -1.2128, -0.4325, -1.4578,  1.8723,
         -0.6218, -0.5993,  2.1806,  0.0591,  3.0450,  1.5159,  0.0215, -0.4878,
          1.7244, -1.3308, -0.3601,  0.5430, -0.8792, -0.5590,  0.0887, -1.8202,
         -1.1549],
        [ 0.8874, -0.9679,  0.6988,  0.4232, -1.3799, -0.9469, -1.1022,  0.5360,
         -0.4993, -0.7194,  1.3024, -0.5645,  3.1953,  1.3062,  1.0682, -1.3468,
          1.2911, -0.1835, -1.0545,  1.0564, -0.8386, -1.0629,  0.2403, -1.7240,
         -1.0509]], dtype=torch.float64, requires_grad=True)
Parameter containing:
tensor([4.0536, 3.2769, 4.2101, 3.4757, 3.8061], dtype=torch.float64,
       requires_grad=True)
Starting Training
layer weights:  Parameter containing:
tensor([[-0.1729, -0.0818, -0.0728, -0.1757, -0.0027, -0.1694,  0.1078, -0.0974,
         -0.0783, -0.0730,  0.1643, -0.0275,  0.1380, -0.1341,  0.1452, -0.0903,
          0.0826, -0.1433, -0.0864, -0.0567, -0.1681,  0.1662, -0.0685, -0.1350,
         -0.1177],
        [-0.0417, -0.0741, -0.0778,  0.0705, -0.0836, -0.0146,  0.1945, -0.1561,
         -0.1086,  0.0413, -0.0271,  0.1136,  0.1040, -0.1294, -0.1902,  0.1687,
         -0.1873,  0.1755, -0.1213,  0.0689, -0.1516, -0.1868, -0.0029,  0.1734,
          0.1953],
        [ 0.0974,  0.0911,  0.0084, -0.0567,  0.1551, -0.0606,  0.1913,  0.0046,
          0.0561, -0.1114,  0.0684,  0.1312, -0.0586,  0.0738, -0.0512,  0.1207,
         -0.1773,  0.1250,  0.0086,  0.1865,  0.0273,  0.0605,  0.1664,  0.0673,
         -0.1455],
        [ 0.0596,  0.1470, -0.0612,  0.0880,  0.0587,  0.1502, -0.0368,  0.1688,
         -0.0723,  0.1414,  0.0020,  0.1429,  0.0270,  0.1345,  0.0012,  0.1227,
         -0.1921, -0.0717,  0.0952,  0.1594,  0.1896, -0.0147, -0.1126, -0.1995,
          0.0135],
        [-0.1455,  0.1401,  0.1485,  0.1876, -0.1699, -0.0499,  0.1113, -0.1198,
          0.0073, -0.0328,  0.0018,  0.0654, -0.0537,  0.0962, -0.1854, -0.0443,
          0.0124, -0.1825, -0.1127,  0.1867,  0.1164,  0.1230,  0.1860, -0.1166,
          0.1844]], dtype=torch.float64, requires_grad=True)
layer weights:  Parameter containing:
tensor([[ 0.0783, -0.1481, -0.1526,  0.1621,  0.0351,  0.1882,  0.1042, -0.1217,
         -0.1799,  0.0102,  0.0052,  0.0676,  0.1090,  0.0083,  0.0958, -0.1530,
          0.0154,  0.1908, -0.0273, -0.0195,  0.0239,  0.0740,  0.0808,  0.1005,
          0.0263],
        [ 0.0567,  0.1721,  0.0073, -0.0165,  0.1985, -0.1365, -0.0311, -0.1612,
          0.1085,  0.0568,  0.0750, -0.0700,  0.1004,  0.0445,  0.1362,  0.1287,
         -0.1345, -0.1227, -0.0548,  0.0901,  0.0335, -0.0743, -0.0960,  0.0882,
         -0.0935],
        [-0.0155, -0.1542, -0.1295,  0.0192, -0.1357,  0.1686,  0.1272,  0.0182,
         -0.0052,  0.0943,  0.1499,  0.1529,  0.0257,  0.1719,  0.1920, -0.1032,
         -0.1268,  0.1075,  0.1324, -0.0590, -0.1327,  0.1595, -0.0313,  0.0442,
          0.1339],
        [-0.1747, -0.0932, -0.0320,  0.1886,  0.0794,  0.1472, -0.1413, -0.1577,
          0.0885, -0.1929, -0.1200, -0.1252,  0.0453, -0.1283,  0.0138, -0.0831,
         -0.1668,  0.1767,  0.1434,  0.0258,  0.1283,  0.0069, -0.0228,  0.0255,
          0.1277],
        [ 0.1127, -0.0007, -0.1815, -0.0423,  0.1338,  0.0354,  0.1638, -0.1873,
         -0.0423,  0.1012,  0.1434, -0.0596, -0.1377, -0.1637,  0.0124,  0.1660,
         -0.0248,  0.1517,  0.1595,  0.0592,  0.1504, -0.1800, -0.1767,  0.1744,
          0.0508]], dtype=torch.float64, requires_grad=True)
Traceback (most recent call last):
  File "/Users/rohanpatel/Desktop/github_repo/Reinforcement Learning/Atari DQN Project/Linear.py", line 403, in <module>
    main()
  File "/Users/rohanpatel/Desktop/github_repo/Reinforcement Learning/Atari DQN Project/Linear.py", line 392, in main
    model.train()
  File "/Users/rohanpatel/Desktop/github_repo/Reinforcement Learning/Atari DQN Project/Q_Learning.py", line 93, in train
    self.train_on_minibatch(self.replay_buffer.sample_minibatch(), self.t)
  File "/Users/rohanpatel/Desktop/github_repo/Reinforcement Learning/Atari DQN Project/Linear.py", line 109, in train_on_minibatch
    loss.backward()
  File "/Users/rohanpatel/Desktop/github_repo/Reinforcement Learning/env/lib/python3.11/site-packages/torch/_tensor.py", line 648, in backward
    torch.autograd.backward(
  File "/Users/rohanpatel/Desktop/github_repo/Reinforcement Learning/env/lib/python3.11/site-packages/torch/autograd/__init__.py", line 353, in backward
    _engine_run_backward(
  File "/Users/rohanpatel/Desktop/github_repo/Reinforcement Learning/env/lib/python3.11/site-packages/torch/autograd/graph.py", line 824, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
